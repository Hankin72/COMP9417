{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d7b7005",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import poisson\n",
    "\n",
    "import pylab\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "import numpy as np\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.decomposition import PCA, IncrementalPCA\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "import time\n",
    "import pylab\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import PCA, IncrementalPCA\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.decomposition import PCA, IncrementalPCA\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost import plot_importance\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import preprocessing\n",
    "\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA, IncrementalPCA\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.decomposition import KernelPCA\n",
    "\n",
    "from sklearn.decomposition import PCA, IncrementalPCA\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import datasets, linear_model, svm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42d40e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start : Wed Apr 28 00:11:43 2021\n",
      "\n",
      "Stop : Wed Apr 28 00:11:43 2021\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Start : %s\\n\" % time.ctime())\n",
    "\n",
    "X = pd.read_csv(\"./MLinTheUnknown-Data/X_train.csv\", header=None)\n",
    "y = pd.read_csv(\"./MLinTheUnknown-Data/y_train.csv\", header=None)\n",
    "\n",
    "X_val = pd.read_csv(\"./MLinTheUnknown-Data/X_val.csv\", header=None)\n",
    "y_val = pd.read_csv(\"./MLinTheUnknown-Data/y_val.csv\", header=None)\n",
    "\n",
    "X_test = pd.read_csv(\"./MLinTheUnknown-Data/X_test.csv\", header=None)\n",
    "\n",
    "print(\"Stop : %s\\n\" % time.ctime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cccd1da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2=[10,8,66,67,64,2,3,83,115,59,74,91,75,72,0,51,76,124,82,11,68,90,84,114,58,122,50,4,116,18,92,17,81,112,106]\n",
    "\n",
    "\n",
    "gini=[3,8,9,11,15,16,19,24,30,33,35,37,57,66,68,69,74,75,77,78,80,81,83,88,91,92,96,97,100,104,112,113,115,123,124]\n",
    "\n",
    "\n",
    "corr =[0,4,5,6,7,8,12,13,14,15,16,17,18,19,20,21,22,25,27,30,34,35,51,68,70,96,97,98,99,100,101,102]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5125492",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1\n",
    "def KNN(X, y, X_val, y_val, X_test, del_index):\n",
    "    \n",
    "    X_train = X[del_index]\n",
    "    X_val = X_val[del_index]\n",
    "\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    X_train = min_max_scaler.fit_transform(X_train)\n",
    "    X_val = min_max_scaler.transform(X_val)\n",
    "\n",
    "    y_train = np.array(y).ravel()\n",
    "    y_val = np.array(y_val).ravel()\n",
    "    \n",
    "    #KNN -classifier\n",
    "    clf_knn = KNeighborsClassifier(\n",
    "            n_neighbors = 1, \n",
    "            weights = 'uniform', \n",
    "            leaf_size =5,\n",
    "            algorithm = 'auto',\n",
    "            p=1)\n",
    "    \n",
    "    clf_knn.fit(X_train, y_train)\n",
    "    y_pred_knn= clf_knn.predict(X_val)\n",
    "    f1_knn= f1_score(y_val, y_pred_knn, average='weighted')\n",
    "    f1_knn =  round(f1_knn,5)\n",
    "    return f1_knn\n",
    "\n",
    "# 2\n",
    "def RF(X, y, X_val, y_val, X_test, del_index):\n",
    "    X_train = X[del_index]\n",
    "    X_val = X_val[del_index]\n",
    "\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    X_train = min_max_scaler.fit_transform(X_train)\n",
    "    X_val = min_max_scaler.transform(X_val)\n",
    "    \n",
    "    y_train = np.array(y).ravel()\n",
    "    y_val = np.array(y_val).ravel()\n",
    "\n",
    "    clf_rf = RandomForestClassifier(n_estimators = 160, \n",
    "                                    criterion='gini', \n",
    "                                    min_samples_leaf= 1, \n",
    "                                    max_features = 'auto',\n",
    "                                    min_samples_split =2,\n",
    "                                    random_state= 0\n",
    "                                   )\n",
    "    \n",
    "    clf_rf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_rf = clf_rf.predict(X_val)\n",
    "    f1_rf= f1_score(y_val, y_pred_rf, average='weighted')\n",
    "    f1_rf= round(f1_rf,5)\n",
    "    return f1_rf\n",
    "\n",
    "# 3\n",
    "def extraTree(X, y, X_val, y_val, X_test, del_index):\n",
    "    \n",
    "    X_train = X[del_index]\n",
    "    X_val = X_val[del_index]\n",
    "\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    X_train = min_max_scaler.fit_transform(X_train)\n",
    "    X_val = min_max_scaler.transform(X_val)\n",
    "    \n",
    "    y_train = np.array(y).ravel()\n",
    "    y_val = np.array(y_val).ravel()\n",
    "      \n",
    "    clf_etc = ExtraTreesClassifier( criterion = 'gini',\n",
    "                                   max_features = 'auto',\n",
    "                                   random_state=0\n",
    "                                  )\n",
    "    clf_etc.fit(X_train, y_train)\n",
    "    y_pred_etc = clf_etc.predict(X_val)\n",
    "\n",
    "    f1_etc= f1_score(y_val, y_pred_etc, average='weighted')\n",
    "    f1_etc =round(f1_etc,5)\n",
    "    return f1_etc\n",
    "\n",
    "# 4\n",
    "def xgboost(X, y, X_val, y_val, X_test, del_index):\n",
    "    \n",
    "    X_train = X[del_index]\n",
    "    X_val = X_val[del_index]\n",
    "    \n",
    "    \n",
    "    X_train = np.array(X_train)\n",
    "    X_val = np.array(X_val)\n",
    "    y_train =np.array(y).ravel()\n",
    "    y_val =np.array(y_val).ravel()\n",
    "    # 归一化\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    X_train = min_max_scaler.fit_transform(X_train)\n",
    "    X_val = min_max_scaler.transform(X_val)\n",
    "\n",
    "    Validation = True\n",
    "    if Validation == True:\n",
    "        model = xgb.XGBClassifier(\n",
    "                max_depth=7,\n",
    "                learning_rate=0.05,\n",
    "                n_estimators=1000,\n",
    " \n",
    "                silent=True,\n",
    "                objective='multi:softmax',\n",
    "        )\n",
    "\n",
    "        model.fit(X_train,y_train)\n",
    "        y_pred_xgb = model.predict(X_val)\n",
    "        f1_xgb = f1_score(y_val, y_pred_xgb, average='weighted')\n",
    "        f1_xgb = round(f1_xgb, 5)\n",
    "        \n",
    "    return f1_xgb\n",
    "\n",
    "# 5\n",
    "def Light_gbm(X, y, X_val, y_val, X_test, del_index):\n",
    "    \n",
    "    X_train = X[del_index]\n",
    "    X_val = X_val[del_index]\n",
    "\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    X_train = min_max_scaler.fit_transform(X_train)\n",
    "    X_val = min_max_scaler.transform(X_val)\n",
    "\n",
    "    y_train = np.array(y).ravel()\n",
    "    y_val = np.array(y_val).ravel()\n",
    "    \n",
    "    gbm = LGBMClassifier(\n",
    "       num_leaves=31,\n",
    "        max_depth = -1, \n",
    "        learning_rate=0.1,\n",
    "        n_estimators= 120, \n",
    "        silent = True,\n",
    "        objective = 'multiclass' )\n",
    "    \n",
    "    gbm.fit(X_train,y_train)\n",
    "    y_pred_gbm = gbm.predict(X_val, num_iteration=46)\n",
    "    f1_gbm = f1_score(y_val, y_pred_gbm, average='weighted')\n",
    "    f1_gbm =round(f1_gbm,5)\n",
    "    \n",
    "    return f1_gbm\n",
    "\n",
    "# 6\n",
    "def GradientBoosting(X, y, X_val, y_val, X_test, del_index):\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    Xtrain = scaler.fit_transform(X)\n",
    "    Xval = scaler.transform(X_val)\n",
    "    \n",
    "    \n",
    "    Xtrain =pd.DataFrame(Xtrain)\n",
    "    Xval = pd.DataFrame(Xval)\n",
    "    \n",
    "    Xtrain = Xtrain[del_index]\n",
    "    Xval = Xval[del_index]\n",
    "    \n",
    "    \n",
    "    \n",
    "    y= np.array(y).ravel()\n",
    "    y_val = np.array(y_val).ravel()\n",
    "    \n",
    "    \n",
    "    Xtrain = np.array(Xtrain)\n",
    "    Xval = np.array(Xval)\n",
    "\n",
    "    \n",
    "    \n",
    "    clf = GradientBoostingClassifier(n_estimators=150)\n",
    "    clf.fit(Xtrain, y)\n",
    "    \n",
    "    pred_y_val = clf.predict(Xval)\n",
    "    \n",
    "\n",
    "    f1_gb = f1_score(y_val, pred_y_val, average='weighted')\n",
    "    f1_gb = round(f1_gb, 5)\n",
    "   \n",
    "    return f1_gb\n",
    "\n",
    "\n",
    "# 7\n",
    "def Bagging(X, y, X_val, y_val, X_test, del_index):\n",
    "    X_train = X[del_index]\n",
    "    X_val = X_val[del_index]\n",
    "    \n",
    "\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    X_train = min_max_scaler.fit_transform(X_train)\n",
    "    X_val = min_max_scaler.transform(X_val)\n",
    "\n",
    "    y_train = np.array(y).ravel()\n",
    "    y_val = np.array(y_val).ravel()\n",
    "    \n",
    "    bagging_model = BaggingClassifier(\n",
    "        base_estimator= ExtraTreeClassifier(criterion = 'entropy',max_features = 'auto',random_state=0),\n",
    "        n_estimators = 170,\n",
    "        max_samples = 6400,\n",
    "        random_state = 20\n",
    "    )  \n",
    "    bagging_model.fit(X_train, y_train )\n",
    "    y_pred_bag = bagging_model.predict(X_val)\n",
    "    \n",
    "    f1_bag= f1_score(y_val, y_pred_bag, average='weighted')\n",
    "    f1_bag = round(f1_bag,5)\n",
    "    \n",
    "    return f1_bag\n",
    "\n",
    "\n",
    "# 8\n",
    "def ada_classifier(X, y, X_val, y_val, X_test, del_index): # Adaboost\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X)\n",
    "    X_val = scaler.transform(X_val)\n",
    "    \n",
    "\n",
    "    X_train = pd.DataFrame(X_train)\n",
    "    X_val = pd.DataFrame(X_val)\n",
    "    \n",
    "    \n",
    "    X_train = X_train[del_index]\n",
    "    X_val = X_val[del_index]\n",
    "    \n",
    "    \n",
    "    X_train = np.array(X_train)\n",
    "    X_val =np.array(X_val)\n",
    "    y_train = np.array(y).ravel()\n",
    "    y_val = np.array(y_val).ravel()\n",
    "    \n",
    "    clf = AdaBoostClassifier(DecisionTreeClassifier(max_depth=12), n_estimators=150)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred_val = clf.predict(X_val)\n",
    "    \n",
    "    f1_ada = f1_score(y_val, y_pred_val, average='weighted')\n",
    "    f1_ada = round(f1_ada,5)\n",
    "    \n",
    "    return f1_ada\n",
    "  \n",
    "# 9\n",
    "def scv_classifier(X, y, X_val, y_val, X_test, del_index):   # SVM method\n",
    "    # normalization\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X) \n",
    "    X_val = scaler.transform(X_val)\n",
    "    \n",
    "    X_train = pd.DataFrame(X_train)\n",
    "    X_val = pd.DataFrame(X_val)\n",
    "    \n",
    "    \n",
    "    X_train = X_train[del_index]\n",
    "    X_val = X_val[del_index]\n",
    "    \n",
    "    \n",
    "    X_train = np.array(X_train)\n",
    "    X_val =np.array(X_val)\n",
    "    y_train = np.array(y).ravel()\n",
    "    y_val = np.array(y_val).ravel()\n",
    "    \n",
    "    \n",
    "    # train\n",
    "    svc = svm.SVC(C=2.0)\n",
    "    svc.fit(X_train, y_train)\n",
    "\n",
    "    y_pred_val = svc.predict(X_val)\n",
    "    f1_svm = f1_score(y_val, y_pred_val, average='weighted')\n",
    "    f1_svm = round(f1_svm,5)\n",
    "    return f1_svm\n",
    "\n",
    "# 10\n",
    "def lr_classfier(X, y, X_val, y_val, X_test, del_index): \n",
    "    scaler = StandardScaler()\n",
    "    Xtrain = scaler.fit_transform(X)\n",
    "    X_val = scaler.transform(X_val)\n",
    "    \n",
    "    \n",
    "    Xtrain =pd.DataFrame(Xtrain)\n",
    "    Xval = pd.DataFrame(X_val)\n",
    "    \n",
    "    Xtrain = Xtrain[del_index]\n",
    "    Xval = Xval[del_index]\n",
    "    \n",
    "    \n",
    "    \n",
    "    y= np.array(y).ravel()\n",
    "    y_val = np.array(y_val).ravel()\n",
    "    \n",
    "    \n",
    "    Xtrain = np.array(Xtrain)\n",
    "    Xval = np.array(Xval)\n",
    "   \n",
    "   \n",
    "    \n",
    "\n",
    "    clf = LogisticRegression(C=10.1,solver = 'newton-cg',max_iter=1000)\n",
    "\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    pred_val_y = clf.predict(X_val)\n",
    "    \n",
    "    f1_lr = f1_score(y_val, pred_val_y, average='weighted')\n",
    "    f1_lr =  round(f1_lr,5)\n",
    "    \n",
    "    return f1_lr\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "036ea788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================\n"
     ]
    }
   ],
   "source": [
    "#  for corr\n",
    "corr_knn = []\n",
    "corr_randomForest =[]\n",
    "\n",
    "corr_extratree =[]\n",
    "corr_xgboost=[]\n",
    "\n",
    "corr_light_gbm =[]\n",
    "corr_gradientBoosting = []\n",
    "\n",
    "corr_bagging= []\n",
    "corr_adaboost = []\n",
    "\n",
    "corr_svm = []\n",
    "corr_logistic_regression = []\n",
    "\n",
    "\n",
    "# 1\n",
    "for i in range(1, len(corr)):\n",
    "    corr_temp = corr[:i]\n",
    "    \n",
    "    f1 = KNN(X, y, X_val, y_val, X_test, corr_temp)\n",
    "    corr_knn.append(f1)\n",
    "print(\"========================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "680fb646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.38615, 0.54887, 0.73903, 0.77179, 0.7979, 0.8859, 0.90194, 0.92605, 0.93358, 0.93819, 0.96515, 0.9727, 0.98024, 0.9824, 0.98383, 0.98814, 0.9885, 0.98742, 0.9885, 0.98885, 0.99137, 0.99208, 0.99173, 0.99244, 0.99244, 0.99317, 0.99353, 0.99389, 0.9946, 0.9946, 0.99388]\n"
     ]
    }
   ],
   "source": [
    "print(corr_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82b1078e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n"
     ]
    }
   ],
   "source": [
    "# 2\n",
    "for i in range(1, len(corr)):\n",
    "    corr_temp = corr[:i]\n",
    "    f2 = RF(X, y, X_val, y_val, X_test, corr_temp)\n",
    "    corr_randomForest.append(f2) \n",
    "    \n",
    "print(\"====================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e88a306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3863, 0.58235, 0.75687, 0.77982, 0.7988, 0.8774, 0.89158, 0.9059, 0.9154, 0.92106, 0.9547, 0.97016, 0.9777, 0.98203, 0.98022, 0.97987, 0.98094, 0.98309, 0.98166, 0.9831, 0.9867, 0.98562, 0.98958, 0.98958, 0.98742, 0.99029, 0.98993, 0.99101, 0.9921, 0.99101, 0.99137]\n"
     ]
    }
   ],
   "source": [
    "print(corr_randomForest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1ee7b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n"
     ]
    }
   ],
   "source": [
    "# 3\n",
    "for i in range(1, len(corr)):\n",
    "    corr_temp = corr[:i]\n",
    "    f3 = extraTree(X, y, X_val, y_val, X_test, corr_temp)\n",
    "    corr_extratree.append(f3) \n",
    "print(\"====================\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c22000dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.38799, 0.57172, 0.75372, 0.78472, 0.81233, 0.89427, 0.90671, 0.92435, 0.93361, 0.93608, 0.96656, 0.97486, 0.98275, 0.98526, 0.9849, 0.98705, 0.98597, 0.98886, 0.98921, 0.99065, 0.98993, 0.99065, 0.99245, 0.99245, 0.99173, 0.99281, 0.99281, 0.99281, 0.99353, 0.99353, 0.99353]\n"
     ]
    }
   ],
   "source": [
    "print(corr_extratree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "88c56b99",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-e721e03d1c40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mcorr_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mf4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgboost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorr_temp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mcorr_xgboost\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-64d9b5ec246a>\u001b[0m in \u001b[0;36mxgboost\u001b[0;34m(X, y, X_val, y_val, X_test, del_index)\u001b[0m\n\u001b[1;32m    104\u001b[0m         )\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m         \u001b[0my_pred_xgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0mf1_xgb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_xgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weighted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/COMP9444/lib/python3.7/site-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, callbacks)\u001b[0m\n\u001b[1;32m    730\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m                               \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxgb_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m                               callbacks=callbacks)\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/COMP9444/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    214\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/COMP9444/lib/python3.7/site-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/COMP9444/lib/python3.7/site-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m-> 1109\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1110\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 4\n",
    "for i in range(1, len(corr)):\n",
    "    corr_temp = corr[:i]\n",
    "    f4 = xgboost(X, y, X_val, y_val, X_test, corr_temp)\n",
    "    corr_xgboost.append(f4) \n",
    "    \n",
    "print(\"====================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b99716e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n"
     ]
    }
   ],
   "source": [
    "# 5\n",
    "for i in range(1, len(corr)):\n",
    "    corr_temp = corr[:i]\n",
    "    f5 = Light_gbm(X, y, X_val, y_val, X_test, corr_temp)\n",
    "    corr_light_gbm.append(f5) \n",
    "    \n",
    "print(\"====================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1feb9f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.47259, 0.58355, 0.707, 0.72571, 0.75778, 0.84498, 0.85961, 0.88672, 0.89119, 0.89154, 0.94567, 0.96156, 0.97411, 0.9813, 0.98093, 0.98057, 0.98129, 0.98166, 0.9813, 0.9813, 0.98562, 0.98669, 0.98813, 0.98634, 0.9885, 0.98742, 0.98957, 0.98993, 0.99065, 0.98957, 0.98886]\n"
     ]
    }
   ],
   "source": [
    "print(corr_light_gbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6af37ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n"
     ]
    }
   ],
   "source": [
    "# 6\n",
    "for i in range(1, len(corr)):\n",
    "    corr_temp = corr[:i]\n",
    "    f6 = GradientBoosting(X, y, X_val, y_val, X_test, corr_temp)\n",
    "    corr_gradientBoosting.append(f6) \n",
    "    \n",
    "print(\"====================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f10ea22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n"
     ]
    }
   ],
   "source": [
    "# 7\n",
    "for i in range(1, len(corr)):\n",
    "    corr_temp = corr[:i]\n",
    "    f7 = Bagging(X, y, X_val, y_val, X_test, corr_temp)\n",
    "    corr_bagging.append(f7) \n",
    "    \n",
    "print(\"====================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9c51f812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n"
     ]
    }
   ],
   "source": [
    "# 8\n",
    "for i in range(1, len(corr)):\n",
    "    corr_temp = corr[:i]\n",
    "    f8 = ada_classifier(X, y, X_val, y_val, X_test, corr_temp)\n",
    "    corr_adaboost.append(f8) \n",
    "    \n",
    "print(\"====================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "981728d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n"
     ]
    }
   ],
   "source": [
    "# 9\n",
    "for i in range(1, len(corr)):\n",
    "    corr_temp = corr[:i]\n",
    "    f9 = scv_classifier(X, y, X_val, y_val, X_test, corr_temp)\n",
    "    corr_svm.append(f9) \n",
    "    \n",
    "print(\"====================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5d264e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/COMP9444/lib/python3.7/site-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/opt/anaconda3/envs/COMP9444/lib/python3.7/site-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/opt/anaconda3/envs/COMP9444/lib/python3.7/site-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/opt/anaconda3/envs/COMP9444/lib/python3.7/site-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/opt/anaconda3/envs/COMP9444/lib/python3.7/site-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/opt/anaconda3/envs/COMP9444/lib/python3.7/site-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/opt/anaconda3/envs/COMP9444/lib/python3.7/site-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/opt/anaconda3/envs/COMP9444/lib/python3.7/site-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/opt/anaconda3/envs/COMP9444/lib/python3.7/site-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n",
      "/opt/anaconda3/envs/COMP9444/lib/python3.7/site-packages/sklearn/utils/optimize.py:212: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-a9f8346a0d0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mcorr_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mf10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr_classfier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorr_temp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mcorr_logistic_regression\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-64d9b5ec246a>\u001b[0m in \u001b[0;36mlr_classfier\u001b[0;34m(X, y, X_val, y_val, X_test, del_index)\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msolver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'newton-cg'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m     \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0mpred_val_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/COMP9444/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1415\u001b[0m                       \u001b[0mpenalty\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_squared_sum\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1416\u001b[0m                       sample_weight=sample_weight)\n\u001b[0;32m-> 1417\u001b[0;31m             for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n\u001b[0m\u001b[1;32m   1418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1419\u001b[0m         \u001b[0mfold_coefs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfold_coefs_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/COMP9444/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1039\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/COMP9444/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/COMP9444/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/COMP9444/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/COMP9444/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/COMP9444/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/COMP9444/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 263\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/COMP9444/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[0;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[1;32m    767\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m             w0, n_iter_i = _newton_cg(hess, func, grad, w0, args=args,\n\u001b[0;32m--> 769\u001b[0;31m                                       maxiter=max_iter, tol=tol)\n\u001b[0m\u001b[1;32m    770\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0msolver\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'liblinear'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m             coef_, intercept_, n_iter_i, = _fit_liblinear(\n",
      "\u001b[0;32m/opt/anaconda3/envs/COMP9444/lib/python3.7/site-packages/sklearn/utils/optimize.py\u001b[0m in \u001b[0;36m_newton_cg\u001b[0;34m(grad_hess, func, grad, x0, args, tol, maxiter, maxinner, line_search, warn)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;31m# Inner loop: solve the Newton update by conjugate gradient, to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;31m# avoid inverting the Hessian\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0mxsupi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_cg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfhess_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxinner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtermcond\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0malphak\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/COMP9444/lib/python3.7/site-packages/sklearn/utils/optimize.py\u001b[0m in \u001b[0;36m_cg\u001b[0;34m(fhess_p, fgrad, maxiter, tol)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0mAp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfhess_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpsupi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;31m# check curvature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0mcurv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpsupi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/COMP9444/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mhessp\u001b[0;34m(v)\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0mhessProd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfit_intercept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m             \u001b[0mhessProd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr_yhat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhessProd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/COMP9444/lib/python3.7/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     45\u001b[0m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n\u001b[1;32m     46\u001b[0m          initial=_NoValue, where=True):\n\u001b[0;32m---> 47\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m def _prod(a, axis=None, dtype=None, out=None, keepdims=False,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 10\n",
    "for i in range(1, len(corr)):\n",
    "    corr_temp = corr[:i]\n",
    "    f10 = lr_classfier(X, y, X_val, y_val, X_test, corr_temp)\n",
    "    corr_logistic_regression.append(f10) \n",
    "    \n",
    "print(\"====================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c60aa44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.38615, 0.54887, 0.73903, 0.77179, 0.7979, 0.8859, 0.90194, 0.92605, 0.93358, 0.93819, 0.96515, 0.9727, 0.98024, 0.9824, 0.98383, 0.98814, 0.9885, 0.98742, 0.9885, 0.98885, 0.99137, 0.99208, 0.99173, 0.99244, 0.99244, 0.99317, 0.99353, 0.99389, 0.9946, 0.9946, 0.99388]\n"
     ]
    }
   ],
   "source": [
    "print(corr_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "12bf82e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3863, 0.58235, 0.75687, 0.77982, 0.7988, 0.8774, 0.89158, 0.9059, 0.9154, 0.92106, 0.9547, 0.97016, 0.9777, 0.98203, 0.98022, 0.97987, 0.98094, 0.98309, 0.98166, 0.9831, 0.9867, 0.98562, 0.98958, 0.98958, 0.98742, 0.99029, 0.98993, 0.99101, 0.9921, 0.99101, 0.99137]\n"
     ]
    }
   ],
   "source": [
    "print(corr_randomForest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ed808eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.38799, 0.57172, 0.75372, 0.78472, 0.81233, 0.89427, 0.90671, 0.92435, 0.93361, 0.93608, 0.96656, 0.97486, 0.98275, 0.98526, 0.9849, 0.98705, 0.98597, 0.98886, 0.98921, 0.99065, 0.98993, 0.99065, 0.99245, 0.99245, 0.99173, 0.99281, 0.99281, 0.99281, 0.99353, 0.99353, 0.99353]\n"
     ]
    }
   ],
   "source": [
    "print(corr_extratree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc6d3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corr_xgboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e42c9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.47259, 0.58355, 0.707, 0.72571, 0.75778, 0.84498, 0.85961, 0.88672, 0.89119, 0.89154, 0.94567, 0.96156, 0.97411, 0.9813, 0.98093, 0.98057, 0.98129, 0.98166, 0.9813, 0.9813, 0.98562, 0.98669, 0.98813, 0.98634, 0.9885, 0.98742, 0.98957, 0.98993, 0.99065, 0.98957, 0.98886]\n"
     ]
    }
   ],
   "source": [
    "print(corr_light_gbm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4a57efc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.46933, 0.56411, 0.66246, 0.68313, 0.70211, 0.79648, 0.8129, 0.83979, 0.84281, 0.8556, 0.91941, 0.93194, 0.96334, 0.97414, 0.97092, 0.97484, 0.97484, 0.97663, 0.97519, 0.97734, 0.98059, 0.98309, 0.98381, 0.98381, 0.98311, 0.9867, 0.98634, 0.98527, 0.98634, 0.98706, 0.98599]\n"
     ]
    }
   ],
   "source": [
    "print(corr_gradientBoosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1ab969",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corr_bagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f436dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corr_adaboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063e7735",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corr_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45aeee13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corr_logistic_regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d492f484",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_knn_1= [0.38615, 0.54887, 0.73903, 0.77179, 0.7979, 0.8859, 0.90194, 0.92605, 0.93358, 0.93819, 0.96515, 0.9727, 0.98024, 0.9824, 0.98383, 0.98814, 0.9885, 0.98742, 0.9885, 0.98885, 0.99137, 0.99208, 0.99173, 0.99244, 0.99244, 0.99317, 0.99353, 0.99389, 0.9946, 0.9946, 0.99388]\n",
    "\n",
    "\n",
    "corr_randomForest_1 = [0.3863, 0.58235, 0.75687, 0.77982, 0.7988, 0.8774, 0.89158, 0.9059, 0.9154, 0.92106, 0.9547, 0.97016, 0.9777, 0.98203, 0.98022, 0.97987, 0.98094, 0.98309, 0.98166, 0.9831, 0.9867, 0.98562, 0.98958, 0.98958, 0.98742, 0.99029, 0.98993, 0.99101, 0.9921, 0.99101, 0.99137]\n",
    "\n",
    "corr_extratree_1 = [0.38799, 0.57172, 0.75372, 0.78472, 0.81233, 0.89427, 0.90671, 0.92435, 0.93361, 0.93608, 0.96656, 0.97486, 0.98275, 0.98526, 0.9849, 0.98705, 0.98597, 0.98886, 0.98921, 0.99065, 0.98993, 0.99065, 0.99245, 0.99245, 0.99173, 0.99281, 0.99281, 0.99281, 0.99353, 0.99353, 0.99353]\n",
    "\n",
    "# corr_xgboost_1=[]\n",
    "\n",
    "corr_light_gbm_1 = [0.47259, 0.58355, 0.707, 0.72571, 0.75778, 0.84498, 0.85961, 0.88672, 0.89119, 0.89154, 0.94567, 0.96156, 0.97411, 0.9813, 0.98093, 0.98057, 0.98129, 0.98166, 0.9813, 0.9813, 0.98562, 0.98669, 0.98813, 0.98634, 0.9885, 0.98742, 0.98957, 0.98993, 0.99065, 0.98957, 0.98886]\n",
    "\n",
    "corr_gradientBoosting_1 = [0.46933, 0.56411, 0.66246, 0.68313, 0.70211, 0.79648, 0.8129, 0.83979, 0.84281, 0.8556, 0.91941, 0.93194, 0.96334, 0.97414, 0.97092, 0.97484, 0.97484, 0.97663, 0.97519, 0.97734, 0.98059, 0.98309, 0.98381, 0.98381, 0.98311, 0.9867, 0.98634, 0.98527, 0.98634, 0.98706, 0.98599]\n",
    "\n",
    "# corr_bagging_1= []\n",
    "# corr_adaboost_1 = []\n",
    "\n",
    "# corr_svm_1 = []\n",
    "# corr_logistic_regression_1 = []\n",
    "\n",
    "\n",
    "x = [i for i in range(1,len(corr))]\n",
    "plt.figure(figsize=(12,10))\n",
    "plt.title(\"Correlation Coefficient-Dims on different models\")\n",
    "# 1\n",
    "plt.plot(x, corr_knn_1, color='blue', label=\"KNN\")\n",
    "# 2\n",
    "plt.plot(x, corr_randomForest_1, color='Orange', label=\"RandomForest\")\n",
    "# 3\n",
    "plt.plot(x, corr_extratree_1, color='Lime', label=\"ExtraTree\")\n",
    "# 4\n",
    "plt.plot(x, corr_xgboost_1, color='Red', label=\"Xgboost\")\n",
    "# 5\n",
    "plt.plot(x, corr_light_gbm_1, color='DarkRed', label=\"Light-gbm\")\n",
    "# 6\n",
    "plt.plot(x, corr_gradientBoosting_1, color='Chocolate', label=\"GradientBoost\")\n",
    "# 7\n",
    "plt.plot(x, corr_bagging_1, color='lightgreen', label=\"Bagging\")\n",
    "# 8\n",
    "plt.plot(x, corr_adaboost_1, color='black', label=\"Adaboost\")\n",
    "# 9\n",
    "plt.plot(x, corr_svm_1, color='Orchid', label=\"SVM\")\n",
    "# 10\n",
    "plt.plot(x, corr_logistic_regression_1, color='lightblue', label=\"LogisticRegression\")\n",
    "# ##############\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.4,linestyle=':')\n",
    "\n",
    "plt.xlabel(\"Num of Features\")\n",
    "# plt.xticks(x, random_sizes, rotation=0)\n",
    "plt.ylabel(\"f1-score(weighted)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840db376",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8905dd0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb900b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
