{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-2eXCsVuPchw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "gYOO-S5KO3ag"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "MBoyRCY6PwH7"
   },
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"/content/drive/MyDrive/Again/X_train.csv\", header=None)\n",
    "y = pd.read_csv(\"/content/drive/MyDrive/Again/y_train.csv\", header=None)\n",
    "X_val = pd.read_csv(\"/content/drive/MyDrive/Again/X_val.csv\", header=None)\n",
    "y_val = pd.read_csv(\"/content/drive/MyDrive/Again/y_val.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "Pe8CK4IbVPfp"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "new_y = np.zeros((y.values.shape[0], 6), dtype=int)\n",
    "for i in range(y.values.shape[0]):\n",
    "  new_y[i, int(y.values.ravel()[i])-1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VfdtQ5DzViDb",
    "outputId": "f6e7a335-9aea-4a2e-e14b-bcf2e770b3fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8346, 6)"
      ]
     },
     "execution_count": 34,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "i0riDji0PwJ9"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout, Concatenate, Lambda, GaussianNoise, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.activations import relu, swish\n",
    "from tensorflow.keras.metrics import AUC\n",
    "# !pip3 install kerastuner\n",
    "# import kerastuner as kt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "OxsMshIzPwMW"
   },
   "outputs": [],
   "source": [
    "def create_autoencoder(input_dim, output_dim, noise=0.05):\n",
    "    i = Input(input_dim)\n",
    "    encoded = BatchNormalization()(i)\n",
    "    encoded = GaussianNoise(noise)(encoded)\n",
    "    \n",
    "    encoded = Dense(64, activation='relu')(encoded)\n",
    "    decoded = Dropout(0.2)(encoded)\n",
    "    decoded = Dense(input_dim, name='decoded')(decoded) \n",
    "    x = Dense(32, activation='relu')(decoded)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(output_dim, activation='sigmoid', name='label_output')(x)\n",
    "\n",
    "    encoder = Model(inputs=i, outputs=encoded)\n",
    "    autoencoder = Model(inputs=i, outputs=[decoded, x]) \n",
    "\n",
    "    autoencoder.compile(optimizer=Adam(0.001), loss={'decoded':'mse', 'label_output':'binary_crossentropy'})\n",
    "\n",
    "    return autoencoder, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4y_V3KebPwOc",
    "outputId": "a137f7e1-7d07-47be-82c6-e2f112a85b0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "2/2 [==============================] - 1s 275ms/step - loss: 2.2310 - decoded_loss: 1.4404 - label_output_loss: 0.7906 - val_loss: 2.2140 - val_decoded_loss: 2.0081 - val_label_output_loss: 0.2058\n",
      "Epoch 2/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: 1.0132 - decoded_loss: 1.4239 - label_output_loss: -0.4107 - val_loss: 1.5600 - val_decoded_loss: 1.9861 - val_label_output_loss: -0.4261\n",
      "Epoch 3/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: 0.0187 - decoded_loss: 1.4046 - label_output_loss: -1.3859 - val_loss: 0.8328 - val_decoded_loss: 1.9634 - val_label_output_loss: -1.1306\n",
      "Epoch 4/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: -0.7118 - decoded_loss: 1.3619 - label_output_loss: -2.0737 - val_loss: 0.1670 - val_decoded_loss: 1.9386 - val_label_output_loss: -1.7716\n",
      "Epoch 5/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: -1.2458 - decoded_loss: 1.3342 - label_output_loss: -2.5800 - val_loss: -0.4238 - val_decoded_loss: 1.9158 - val_label_output_loss: -2.3396\n",
      "Epoch 6/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: -1.7420 - decoded_loss: 1.2888 - label_output_loss: -3.0308 - val_loss: -0.9903 - val_decoded_loss: 1.8974 - val_label_output_loss: -2.8877\n",
      "Epoch 7/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: -2.2597 - decoded_loss: 1.2745 - label_output_loss: -3.5342 - val_loss: -1.5826 - val_decoded_loss: 1.8843 - val_label_output_loss: -3.4669\n",
      "Epoch 8/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: -2.7146 - decoded_loss: 1.2373 - label_output_loss: -3.9519 - val_loss: -2.1151 - val_decoded_loss: 1.8730 - val_label_output_loss: -3.9882\n",
      "Epoch 9/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: -3.1947 - decoded_loss: 1.2330 - label_output_loss: -4.4277 - val_loss: -2.5665 - val_decoded_loss: 1.8634 - val_label_output_loss: -4.4299\n",
      "Epoch 10/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: -3.5409 - decoded_loss: 1.2202 - label_output_loss: -4.7611 - val_loss: -2.9484 - val_decoded_loss: 1.8548 - val_label_output_loss: -4.8032\n",
      "Epoch 11/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: -3.9768 - decoded_loss: 1.1963 - label_output_loss: -5.1730 - val_loss: -3.2371 - val_decoded_loss: 1.8429 - val_label_output_loss: -5.0800\n",
      "Epoch 12/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: -4.2259 - decoded_loss: 1.2048 - label_output_loss: -5.4307 - val_loss: -3.5053 - val_decoded_loss: 1.8306 - val_label_output_loss: -5.3359\n",
      "Epoch 13/1000\n",
      "2/2 [==============================] - 0s 45ms/step - loss: -4.6447 - decoded_loss: 1.1739 - label_output_loss: -5.8186 - val_loss: -3.8405 - val_decoded_loss: 1.8178 - val_label_output_loss: -5.6582\n",
      "Epoch 14/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: -5.0264 - decoded_loss: 1.1603 - label_output_loss: -6.1867 - val_loss: -4.2074 - val_decoded_loss: 1.8034 - val_label_output_loss: -6.0108\n",
      "Epoch 15/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: -5.5211 - decoded_loss: 1.1272 - label_output_loss: -6.6483 - val_loss: -4.6028 - val_decoded_loss: 1.7886 - val_label_output_loss: -6.3914\n",
      "Epoch 16/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: -5.8295 - decoded_loss: 1.1114 - label_output_loss: -6.9409 - val_loss: -4.8084 - val_decoded_loss: 1.7734 - val_label_output_loss: -6.5818\n",
      "Epoch 17/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: -6.1520 - decoded_loss: 1.1158 - label_output_loss: -7.2679 - val_loss: -4.9708 - val_decoded_loss: 1.7581 - val_label_output_loss: -6.7289\n",
      "Epoch 18/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: -6.5163 - decoded_loss: 1.1123 - label_output_loss: -7.6285 - val_loss: -5.4508 - val_decoded_loss: 1.7447 - val_label_output_loss: -7.1955\n",
      "Epoch 19/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: -6.8317 - decoded_loss: 1.0975 - label_output_loss: -7.9291 - val_loss: -5.6570 - val_decoded_loss: 1.7302 - val_label_output_loss: -7.3872\n",
      "Epoch 20/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: -7.0715 - decoded_loss: 1.0992 - label_output_loss: -8.1707 - val_loss: -5.5744 - val_decoded_loss: 1.7157 - val_label_output_loss: -7.2901\n",
      "Epoch 21/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: -7.5481 - decoded_loss: 1.0557 - label_output_loss: -8.6039 - val_loss: -5.7740 - val_decoded_loss: 1.7068 - val_label_output_loss: -7.4808\n",
      "Epoch 22/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: -7.7661 - decoded_loss: 1.0598 - label_output_loss: -8.8258 - val_loss: -6.0671 - val_decoded_loss: 1.7014 - val_label_output_loss: -7.7685\n",
      "Epoch 23/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: -8.1272 - decoded_loss: 1.0593 - label_output_loss: -9.1865 - val_loss: -6.7874 - val_decoded_loss: 1.6999 - val_label_output_loss: -8.4872\n",
      "Epoch 24/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: -8.3122 - decoded_loss: 1.0423 - label_output_loss: -9.3545 - val_loss: -6.8684 - val_decoded_loss: 1.6953 - val_label_output_loss: -8.5637\n",
      "Epoch 25/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: -8.6568 - decoded_loss: 1.0656 - label_output_loss: -9.7224 - val_loss: -6.9717 - val_decoded_loss: 1.6883 - val_label_output_loss: -8.6601\n",
      "Epoch 26/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: -8.9570 - decoded_loss: 1.0563 - label_output_loss: -10.0133 - val_loss: -8.0997 - val_decoded_loss: 1.6838 - val_label_output_loss: -9.7834\n",
      "Epoch 27/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: -9.3083 - decoded_loss: 1.0355 - label_output_loss: -10.3438 - val_loss: -9.0701 - val_decoded_loss: 1.6787 - val_label_output_loss: -10.7488\n",
      "Epoch 28/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: -9.6748 - decoded_loss: 1.0284 - label_output_loss: -10.7032 - val_loss: -8.7407 - val_decoded_loss: 1.6687 - val_label_output_loss: -10.4094\n",
      "Epoch 29/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: -9.9160 - decoded_loss: 1.0341 - label_output_loss: -10.9501 - val_loss: -8.8117 - val_decoded_loss: 1.6617 - val_label_output_loss: -10.4733\n",
      "Epoch 30/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: -10.1194 - decoded_loss: 0.9975 - label_output_loss: -11.1169 - val_loss: -9.8507 - val_decoded_loss: 1.6576 - val_label_output_loss: -11.5084\n",
      "Epoch 31/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: -10.4288 - decoded_loss: 1.0257 - label_output_loss: -11.4545 - val_loss: -9.8730 - val_decoded_loss: 1.6489 - val_label_output_loss: -11.5219\n",
      "Epoch 32/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: -10.7324 - decoded_loss: 0.9995 - label_output_loss: -11.7319 - val_loss: -9.9033 - val_decoded_loss: 1.6399 - val_label_output_loss: -11.5432\n",
      "Epoch 33/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: -10.9737 - decoded_loss: 1.0062 - label_output_loss: -11.9799 - val_loss: -9.8584 - val_decoded_loss: 1.6301 - val_label_output_loss: -11.4885\n",
      "Epoch 34/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: -11.2971 - decoded_loss: 1.0060 - label_output_loss: -12.3030 - val_loss: -10.5374 - val_decoded_loss: 1.6230 - val_label_output_loss: -12.1604\n",
      "Epoch 35/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: -11.6470 - decoded_loss: 1.0017 - label_output_loss: -12.6487 - val_loss: -10.7901 - val_decoded_loss: 1.6153 - val_label_output_loss: -12.4054\n",
      "Epoch 36/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: -11.8544 - decoded_loss: 0.9794 - label_output_loss: -12.8338 - val_loss: -10.8599 - val_decoded_loss: 1.6074 - val_label_output_loss: -12.4673\n",
      "Epoch 37/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: -12.1038 - decoded_loss: 0.9856 - label_output_loss: -13.0894 - val_loss: -11.2360 - val_decoded_loss: 1.6006 - val_label_output_loss: -12.8366\n",
      "Epoch 38/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: -12.3977 - decoded_loss: 0.9756 - label_output_loss: -13.3734 - val_loss: -10.6807 - val_decoded_loss: 1.5923 - val_label_output_loss: -12.2730\n",
      "Epoch 39/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: -12.7631 - decoded_loss: 0.9509 - label_output_loss: -13.7140 - val_loss: -11.2478 - val_decoded_loss: 1.5880 - val_label_output_loss: -12.8358\n",
      "Epoch 40/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: -12.9494 - decoded_loss: 0.9675 - label_output_loss: -13.9169 - val_loss: -11.3442 - val_decoded_loss: 1.5805 - val_label_output_loss: -12.9247\n",
      "Epoch 41/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: -13.2695 - decoded_loss: 0.9353 - label_output_loss: -14.2048 - val_loss: -11.9185 - val_decoded_loss: 1.5732 - val_label_output_loss: -13.4917\n",
      "Epoch 42/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: -13.5409 - decoded_loss: 0.9306 - label_output_loss: -14.4715 - val_loss: -11.6640 - val_decoded_loss: 1.5645 - val_label_output_loss: -13.2285\n",
      "Epoch 43/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: -13.8432 - decoded_loss: 0.9448 - label_output_loss: -14.7879 - val_loss: -11.7098 - val_decoded_loss: 1.5578 - val_label_output_loss: -13.2676\n",
      "Epoch 44/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: -14.1036 - decoded_loss: 0.9389 - label_output_loss: -15.0425 - val_loss: -12.8801 - val_decoded_loss: 1.5542 - val_label_output_loss: -14.4344\n",
      "Epoch 45/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: -14.3624 - decoded_loss: 0.9268 - label_output_loss: -15.2892 - val_loss: -12.3520 - val_decoded_loss: 1.5463 - val_label_output_loss: -13.8983\n",
      "Epoch 46/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: -14.5334 - decoded_loss: 0.9248 - label_output_loss: -15.4582 - val_loss: -12.1734 - val_decoded_loss: 1.5402 - val_label_output_loss: -13.7136\n",
      "Epoch 47/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: -14.9553 - decoded_loss: 0.8959 - label_output_loss: -15.8513 - val_loss: -13.6047 - val_decoded_loss: 1.5386 - val_label_output_loss: -15.1433\n",
      "Epoch 48/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: -15.1828 - decoded_loss: 0.9061 - label_output_loss: -16.0890 - val_loss: -12.9795 - val_decoded_loss: 1.5322 - val_label_output_loss: -14.5117\n",
      "Epoch 49/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: -15.4007 - decoded_loss: 0.9001 - label_output_loss: -16.3008 - val_loss: -11.8522 - val_decoded_loss: 1.5246 - val_label_output_loss: -13.3768\n",
      "Epoch 50/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: -15.6379 - decoded_loss: 0.8984 - label_output_loss: -16.5363 - val_loss: -13.8777 - val_decoded_loss: 1.5219 - val_label_output_loss: -15.3995\n",
      "Epoch 51/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: -15.9212 - decoded_loss: 0.8586 - label_output_loss: -16.7798 - val_loss: -14.2379 - val_decoded_loss: 1.5160 - val_label_output_loss: -15.7538\n",
      "Epoch 52/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: -16.3736 - decoded_loss: 0.8701 - label_output_loss: -17.2438 - val_loss: -13.1020 - val_decoded_loss: 1.5080 - val_label_output_loss: -14.6100\n",
      "Epoch 53/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: -16.5225 - decoded_loss: 0.8684 - label_output_loss: -17.3909 - val_loss: -13.7465 - val_decoded_loss: 1.5045 - val_label_output_loss: -15.2510\n",
      "Epoch 54/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: -16.8552 - decoded_loss: 0.8687 - label_output_loss: -17.7239 - val_loss: -15.6182 - val_decoded_loss: 1.5046 - val_label_output_loss: -17.1228\n",
      "Epoch 55/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: -17.0659 - decoded_loss: 0.8622 - label_output_loss: -17.9281 - val_loss: -14.5809 - val_decoded_loss: 1.4985 - val_label_output_loss: -16.0794\n",
      "Epoch 56/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: -17.4587 - decoded_loss: 0.8392 - label_output_loss: -18.2979 - val_loss: -13.5243 - val_decoded_loss: 1.4940 - val_label_output_loss: -15.0182\n",
      "Epoch 57/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: -17.7321 - decoded_loss: 0.8456 - label_output_loss: -18.5777 - val_loss: -15.4416 - val_decoded_loss: 1.4935 - val_label_output_loss: -16.9351\n",
      "Epoch 58/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: -17.9467 - decoded_loss: 0.8522 - label_output_loss: -18.7989 - val_loss: -15.9215 - val_decoded_loss: 1.4889 - val_label_output_loss: -17.4104\n",
      "Epoch 59/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: -18.3330 - decoded_loss: 0.8335 - label_output_loss: -19.1664 - val_loss: -14.8635 - val_decoded_loss: 1.4816 - val_label_output_loss: -16.3451\n",
      "Epoch 60/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: -18.5795 - decoded_loss: 0.8153 - label_output_loss: -19.3948 - val_loss: -15.6786 - val_decoded_loss: 1.4770 - val_label_output_loss: -17.1556\n",
      "Epoch 61/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: -18.9707 - decoded_loss: 0.8087 - label_output_loss: -19.7794 - val_loss: -16.6858 - val_decoded_loss: 1.4737 - val_label_output_loss: -18.1594\n",
      "Epoch 62/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: -19.2727 - decoded_loss: 0.8048 - label_output_loss: -20.0776 - val_loss: -16.0738 - val_decoded_loss: 1.4682 - val_label_output_loss: -17.5419\n",
      "Epoch 63/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: -19.4672 - decoded_loss: 0.8198 - label_output_loss: -20.2871 - val_loss: -15.7479 - val_decoded_loss: 1.4633 - val_label_output_loss: -17.2112\n",
      "Epoch 64/1000\n",
      "2/2 [==============================] - 0s 64ms/step - loss: -19.8754 - decoded_loss: 0.8031 - label_output_loss: -20.6785 - val_loss: -16.8571 - val_decoded_loss: 1.4594 - val_label_output_loss: -18.3165\n",
      "Epoch 65/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: -20.0390 - decoded_loss: 0.7745 - label_output_loss: -20.8134 - val_loss: -16.2214 - val_decoded_loss: 1.4535 - val_label_output_loss: -17.6749\n",
      "Epoch 66/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: -20.4244 - decoded_loss: 0.7704 - label_output_loss: -21.1948 - val_loss: -16.1974 - val_decoded_loss: 1.4486 - val_label_output_loss: -17.6460\n",
      "Epoch 67/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: -20.6899 - decoded_loss: 0.7842 - label_output_loss: -21.4740 - val_loss: -17.7315 - val_decoded_loss: 1.4434 - val_label_output_loss: -19.1749\n",
      "Epoch 68/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: -21.0781 - decoded_loss: 0.7591 - label_output_loss: -21.8372 - val_loss: -17.9436 - val_decoded_loss: 1.4371 - val_label_output_loss: -19.3807\n",
      "Epoch 69/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: -21.3712 - decoded_loss: 0.7566 - label_output_loss: -22.1278 - val_loss: -17.3573 - val_decoded_loss: 1.4306 - val_label_output_loss: -18.7879\n",
      "Epoch 70/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: -21.7086 - decoded_loss: 0.7557 - label_output_loss: -22.4643 - val_loss: -17.6932 - val_decoded_loss: 1.4254 - val_label_output_loss: -19.1186\n",
      "Epoch 71/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: -22.0381 - decoded_loss: 0.7229 - label_output_loss: -22.7610 - val_loss: -18.6757 - val_decoded_loss: 1.4205 - val_label_output_loss: -20.0962\n",
      "Epoch 72/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: -22.3103 - decoded_loss: 0.7586 - label_output_loss: -23.0689 - val_loss: -18.5382 - val_decoded_loss: 1.4145 - val_label_output_loss: -19.9527\n",
      "Epoch 73/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: -22.5781 - decoded_loss: 0.7335 - label_output_loss: -23.3115 - val_loss: -19.1224 - val_decoded_loss: 1.4101 - val_label_output_loss: -20.5324\n",
      "Epoch 74/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: -22.8574 - decoded_loss: 0.7395 - label_output_loss: -23.5968 - val_loss: -19.0539 - val_decoded_loss: 1.4070 - val_label_output_loss: -20.4609\n",
      "Epoch 75/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: -23.3134 - decoded_loss: 0.7331 - label_output_loss: -24.0465 - val_loss: -18.2353 - val_decoded_loss: 1.4042 - val_label_output_loss: -19.6396\n",
      "Epoch 76/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: -23.5926 - decoded_loss: 0.6947 - label_output_loss: -24.2873 - val_loss: -19.4412 - val_decoded_loss: 1.4013 - val_label_output_loss: -20.8425\n",
      "Epoch 77/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: -23.9903 - decoded_loss: 0.7268 - label_output_loss: -24.7172 - val_loss: -19.0908 - val_decoded_loss: 1.3961 - val_label_output_loss: -20.4868\n",
      "Epoch 78/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: -24.2520 - decoded_loss: 0.7191 - label_output_loss: -24.9711 - val_loss: -19.9269 - val_decoded_loss: 1.3916 - val_label_output_loss: -21.3185\n",
      "Epoch 79/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: -24.4808 - decoded_loss: 0.6930 - label_output_loss: -25.1738 - val_loss: -20.3761 - val_decoded_loss: 1.3883 - val_label_output_loss: -21.7644\n",
      "Epoch 80/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: -24.9675 - decoded_loss: 0.7034 - label_output_loss: -25.6709 - val_loss: -20.2137 - val_decoded_loss: 1.3842 - val_label_output_loss: -21.5978\n",
      "Epoch 81/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: -25.3280 - decoded_loss: 0.6834 - label_output_loss: -26.0115 - val_loss: -20.2247 - val_decoded_loss: 1.3798 - val_label_output_loss: -21.6045\n",
      "Epoch 82/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: -25.5529 - decoded_loss: 0.6851 - label_output_loss: -26.2379 - val_loss: -20.5464 - val_decoded_loss: 1.3761 - val_label_output_loss: -21.9225\n",
      "Epoch 83/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: -26.0068 - decoded_loss: 0.6648 - label_output_loss: -26.6715 - val_loss: -20.3635 - val_decoded_loss: 1.3710 - val_label_output_loss: -21.7346\n",
      "Epoch 84/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: -26.2273 - decoded_loss: 0.6568 - label_output_loss: -26.8842 - val_loss: -21.8708 - val_decoded_loss: 1.3678 - val_label_output_loss: -23.2386\n",
      "Epoch 85/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: -26.7014 - decoded_loss: 0.6603 - label_output_loss: -27.3616 - val_loss: -22.1789 - val_decoded_loss: 1.3659 - val_label_output_loss: -23.5448\n",
      "Epoch 86/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: -26.9297 - decoded_loss: 0.6484 - label_output_loss: -27.5781 - val_loss: -21.8997 - val_decoded_loss: 1.3638 - val_label_output_loss: -23.2635\n",
      "Epoch 87/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: -27.2478 - decoded_loss: 0.6623 - label_output_loss: -27.9101 - val_loss: -22.0715 - val_decoded_loss: 1.3618 - val_label_output_loss: -23.4333\n",
      "Epoch 88/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: -27.6335 - decoded_loss: 0.6495 - label_output_loss: -28.2830 - val_loss: -22.1164 - val_decoded_loss: 1.3587 - val_label_output_loss: -23.4751\n",
      "Epoch 89/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: -28.0687 - decoded_loss: 0.6528 - label_output_loss: -28.7215 - val_loss: -22.2610 - val_decoded_loss: 1.3546 - val_label_output_loss: -23.6155\n",
      "Epoch 90/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: -28.4310 - decoded_loss: 0.6252 - label_output_loss: -29.0562 - val_loss: -23.9810 - val_decoded_loss: 1.3528 - val_label_output_loss: -25.3338\n",
      "Epoch 91/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: -28.7231 - decoded_loss: 0.6393 - label_output_loss: -29.3624 - val_loss: -24.3535 - val_decoded_loss: 1.3482 - val_label_output_loss: -25.7017\n",
      "Epoch 92/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: -29.1298 - decoded_loss: 0.6403 - label_output_loss: -29.7702 - val_loss: -23.8148 - val_decoded_loss: 1.3457 - val_label_output_loss: -25.1605\n",
      "Epoch 93/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: -29.5236 - decoded_loss: 0.6175 - label_output_loss: -30.1411 - val_loss: -25.0833 - val_decoded_loss: 1.3477 - val_label_output_loss: -26.4309\n",
      "Epoch 94/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: -29.7669 - decoded_loss: 0.6107 - label_output_loss: -30.3776 - val_loss: -23.5676 - val_decoded_loss: 1.3457 - val_label_output_loss: -24.9132\n",
      "Epoch 95/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: -30.2424 - decoded_loss: 0.6210 - label_output_loss: -30.8634 - val_loss: -23.3062 - val_decoded_loss: 1.3434 - val_label_output_loss: -24.6497\n",
      "Epoch 96/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: -30.4517 - decoded_loss: 0.5964 - label_output_loss: -31.0482 - val_loss: -24.6875 - val_decoded_loss: 1.3413 - val_label_output_loss: -26.0288\n",
      "Epoch 97/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: -30.9096 - decoded_loss: 0.5990 - label_output_loss: -31.5086 - val_loss: -25.0375 - val_decoded_loss: 1.3383 - val_label_output_loss: -26.3758\n",
      "Epoch 98/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: -31.3300 - decoded_loss: 0.6112 - label_output_loss: -31.9413 - val_loss: -25.6255 - val_decoded_loss: 1.3355 - val_label_output_loss: -26.9609\n",
      "Epoch 99/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: -31.7268 - decoded_loss: 0.5999 - label_output_loss: -32.3267 - val_loss: -26.4588 - val_decoded_loss: 1.3345 - val_label_output_loss: -27.7933\n",
      "Epoch 100/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: -32.2361 - decoded_loss: 0.6086 - label_output_loss: -32.8447 - val_loss: -27.5306 - val_decoded_loss: 1.3317 - val_label_output_loss: -28.8622\n",
      "Epoch 101/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: -32.4217 - decoded_loss: 0.5849 - label_output_loss: -33.0066 - val_loss: -27.4825 - val_decoded_loss: 1.3277 - val_label_output_loss: -28.8101\n",
      "Epoch 102/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: -32.6941 - decoded_loss: 0.5691 - label_output_loss: -33.2632 - val_loss: -28.7348 - val_decoded_loss: 1.3256 - val_label_output_loss: -30.0603\n",
      "Epoch 103/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: -33.1227 - decoded_loss: 0.5941 - label_output_loss: -33.7169 - val_loss: -28.6394 - val_decoded_loss: 1.3219 - val_label_output_loss: -29.9613\n",
      "Epoch 104/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: -33.5568 - decoded_loss: 0.5709 - label_output_loss: -34.1277 - val_loss: -29.7374 - val_decoded_loss: 1.3207 - val_label_output_loss: -31.0581\n",
      "Epoch 105/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: -33.8363 - decoded_loss: 0.5838 - label_output_loss: -34.4201 - val_loss: -30.9790 - val_decoded_loss: 1.3214 - val_label_output_loss: -32.3003\n",
      "Epoch 106/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: -34.1367 - decoded_loss: 0.5791 - label_output_loss: -34.7157 - val_loss: -31.4079 - val_decoded_loss: 1.3206 - val_label_output_loss: -32.7285\n",
      "Epoch 107/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: -34.8960 - decoded_loss: 0.5848 - label_output_loss: -35.4808 - val_loss: -32.9789 - val_decoded_loss: 1.3185 - val_label_output_loss: -34.2974\n",
      "Epoch 108/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: -35.0255 - decoded_loss: 0.5906 - label_output_loss: -35.6160 - val_loss: -33.6579 - val_decoded_loss: 1.3160 - val_label_output_loss: -34.9739\n",
      "Epoch 109/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: -35.7005 - decoded_loss: 0.5805 - label_output_loss: -36.2810 - val_loss: -33.8401 - val_decoded_loss: 1.3127 - val_label_output_loss: -35.1528\n",
      "Epoch 110/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: -36.0095 - decoded_loss: 0.5608 - label_output_loss: -36.5702 - val_loss: -34.4718 - val_decoded_loss: 1.3105 - val_label_output_loss: -35.7823\n",
      "Epoch 111/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: -36.4399 - decoded_loss: 0.5749 - label_output_loss: -37.0148 - val_loss: -34.1730 - val_decoded_loss: 1.3087 - val_label_output_loss: -35.4817\n",
      "Epoch 112/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: -36.8379 - decoded_loss: 0.5882 - label_output_loss: -37.4261 - val_loss: -35.0249 - val_decoded_loss: 1.3085 - val_label_output_loss: -36.3335\n",
      "Epoch 113/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: -37.2011 - decoded_loss: 0.5589 - label_output_loss: -37.7600 - val_loss: -35.9394 - val_decoded_loss: 1.3093 - val_label_output_loss: -37.2487\n",
      "Epoch 114/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: -37.6072 - decoded_loss: 0.5693 - label_output_loss: -38.1765 - val_loss: -34.8965 - val_decoded_loss: 1.3095 - val_label_output_loss: -36.2061\n",
      "Epoch 115/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: -38.1886 - decoded_loss: 0.5503 - label_output_loss: -38.7389 - val_loss: -35.1638 - val_decoded_loss: 1.3087 - val_label_output_loss: -36.4725\n",
      "Epoch 116/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: -38.4677 - decoded_loss: 0.5535 - label_output_loss: -39.0212 - val_loss: -36.0109 - val_decoded_loss: 1.3071 - val_label_output_loss: -37.3180\n",
      "Epoch 117/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: -38.8679 - decoded_loss: 0.5515 - label_output_loss: -39.4194 - val_loss: -36.6658 - val_decoded_loss: 1.3051 - val_label_output_loss: -37.9709\n",
      "Epoch 118/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: -39.2525 - decoded_loss: 0.5339 - label_output_loss: -39.7864 - val_loss: -37.0112 - val_decoded_loss: 1.3052 - val_label_output_loss: -38.3164\n",
      "Epoch 119/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: -39.5266 - decoded_loss: 0.5398 - label_output_loss: -40.0664 - val_loss: -36.7752 - val_decoded_loss: 1.3077 - val_label_output_loss: -38.0830\n",
      "Epoch 120/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: -39.8636 - decoded_loss: 0.5499 - label_output_loss: -40.4134 - val_loss: -37.2224 - val_decoded_loss: 1.3085 - val_label_output_loss: -38.5309\n",
      "Epoch 121/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: -40.8520 - decoded_loss: 0.5312 - label_output_loss: -41.3833 - val_loss: -38.6556 - val_decoded_loss: 1.3119 - val_label_output_loss: -39.9675\n",
      "Epoch 122/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: -40.9970 - decoded_loss: 0.5304 - label_output_loss: -41.5274 - val_loss: -39.5412 - val_decoded_loss: 1.3179 - val_label_output_loss: -40.8591\n",
      "Epoch 123/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: -41.3302 - decoded_loss: 0.5491 - label_output_loss: -41.8793 - val_loss: -38.6301 - val_decoded_loss: 1.3213 - val_label_output_loss: -39.9514\n",
      "Epoch 124/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: -41.7407 - decoded_loss: 0.5439 - label_output_loss: -42.2846 - val_loss: -38.9871 - val_decoded_loss: 1.3231 - val_label_output_loss: -40.3102\n",
      "Epoch 125/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: -42.2900 - decoded_loss: 0.5296 - label_output_loss: -42.8196 - val_loss: -39.7614 - val_decoded_loss: 1.3236 - val_label_output_loss: -41.0850\n",
      "Epoch 126/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: -42.5086 - decoded_loss: 0.5223 - label_output_loss: -43.0309 - val_loss: -40.0332 - val_decoded_loss: 1.3245 - val_label_output_loss: -41.3577\n",
      "Epoch 127/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: -43.1515 - decoded_loss: 0.5171 - label_output_loss: -43.6686 - val_loss: -41.2499 - val_decoded_loss: 1.3275 - val_label_output_loss: -42.5774\n",
      "Epoch 128/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: -43.6076 - decoded_loss: 0.5394 - label_output_loss: -44.1470 - val_loss: -40.7027 - val_decoded_loss: 1.3312 - val_label_output_loss: -42.0339\n",
      "Epoch 129/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: -43.8048 - decoded_loss: 0.5188 - label_output_loss: -44.3236 - val_loss: -40.8797 - val_decoded_loss: 1.3371 - val_label_output_loss: -42.2169\n",
      "Epoch 130/1000\n",
      "2/2 [==============================] - 0s 46ms/step - loss: -44.1846 - decoded_loss: 0.5096 - label_output_loss: -44.6942 - val_loss: -41.2296 - val_decoded_loss: 1.3414 - val_label_output_loss: -42.5710\n",
      "Epoch 131/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: -44.3401 - decoded_loss: 0.5208 - label_output_loss: -44.8610 - val_loss: -41.9356 - val_decoded_loss: 1.3472 - val_label_output_loss: -43.2829\n",
      "Epoch 132/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: -45.1026 - decoded_loss: 0.5208 - label_output_loss: -45.6234 - val_loss: -43.9404 - val_decoded_loss: 1.3530 - val_label_output_loss: -45.2933\n",
      "Epoch 133/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: -45.7845 - decoded_loss: 0.5058 - label_output_loss: -46.2903 - val_loss: -44.2388 - val_decoded_loss: 1.3565 - val_label_output_loss: -45.5953\n",
      "Epoch 134/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: -46.1611 - decoded_loss: 0.5042 - label_output_loss: -46.6653 - val_loss: -44.2727 - val_decoded_loss: 1.3622 - val_label_output_loss: -45.6348\n",
      "Epoch 135/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: -46.5312 - decoded_loss: 0.5206 - label_output_loss: -47.0518 - val_loss: -43.4123 - val_decoded_loss: 1.3674 - val_label_output_loss: -44.7797\n",
      "Epoch 136/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: -47.0742 - decoded_loss: 0.5076 - label_output_loss: -47.5818 - val_loss: -43.8926 - val_decoded_loss: 1.3736 - val_label_output_loss: -45.2662\n",
      "Epoch 137/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: -47.4715 - decoded_loss: 0.5180 - label_output_loss: -47.9896 - val_loss: -45.1557 - val_decoded_loss: 1.3768 - val_label_output_loss: -46.5324\n",
      "Epoch 138/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: -47.8170 - decoded_loss: 0.5070 - label_output_loss: -48.3239 - val_loss: -46.3478 - val_decoded_loss: 1.3809 - val_label_output_loss: -47.7287\n",
      "Epoch 139/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: -48.5028 - decoded_loss: 0.5221 - label_output_loss: -49.0249 - val_loss: -46.2551 - val_decoded_loss: 1.3876 - val_label_output_loss: -47.6427\n",
      "Epoch 140/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: -48.8724 - decoded_loss: 0.4931 - label_output_loss: -49.3655 - val_loss: -46.1594 - val_decoded_loss: 1.3949 - val_label_output_loss: -47.5543\n",
      "Epoch 141/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: -49.1872 - decoded_loss: 0.5208 - label_output_loss: -49.7080 - val_loss: -45.7423 - val_decoded_loss: 1.3991 - val_label_output_loss: -47.1414\n",
      "Epoch 142/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: -49.6633 - decoded_loss: 0.5085 - label_output_loss: -50.1718 - val_loss: -46.9318 - val_decoded_loss: 1.4017 - val_label_output_loss: -48.3335\n",
      "Epoch 143/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: -50.1946 - decoded_loss: 0.4958 - label_output_loss: -50.6903 - val_loss: -47.4458 - val_decoded_loss: 1.4048 - val_label_output_loss: -48.8505\n",
      "Epoch 144/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: -50.7179 - decoded_loss: 0.5040 - label_output_loss: -51.2219 - val_loss: -48.5631 - val_decoded_loss: 1.4079 - val_label_output_loss: -49.9710\n",
      "Epoch 145/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: -51.0723 - decoded_loss: 0.4877 - label_output_loss: -51.5600 - val_loss: -48.2535 - val_decoded_loss: 1.4145 - val_label_output_loss: -49.6680\n",
      "Epoch 146/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: -51.6557 - decoded_loss: 0.5129 - label_output_loss: -52.1686 - val_loss: -49.1495 - val_decoded_loss: 1.4284 - val_label_output_loss: -50.5779\n",
      "Epoch 147/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: -52.1955 - decoded_loss: 0.5043 - label_output_loss: -52.6998 - val_loss: -48.0802 - val_decoded_loss: 1.4346 - val_label_output_loss: -49.5148\n",
      "Epoch 148/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: -52.4793 - decoded_loss: 0.4926 - label_output_loss: -52.9719 - val_loss: -50.7526 - val_decoded_loss: 1.4510 - val_label_output_loss: -52.2037\n",
      "Epoch 149/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: -52.6791 - decoded_loss: 0.5022 - label_output_loss: -53.1813 - val_loss: -51.6076 - val_decoded_loss: 1.4616 - val_label_output_loss: -53.0692\n",
      "Epoch 150/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: -53.7365 - decoded_loss: 0.5032 - label_output_loss: -54.2398 - val_loss: -49.5851 - val_decoded_loss: 1.4674 - val_label_output_loss: -51.0525\n",
      "Epoch 151/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: -53.6703 - decoded_loss: 0.4855 - label_output_loss: -54.1558 - val_loss: -52.5011 - val_decoded_loss: 1.4856 - val_label_output_loss: -53.9867\n",
      "Epoch 152/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: -54.3858 - decoded_loss: 0.5094 - label_output_loss: -54.8952 - val_loss: -48.8813 - val_decoded_loss: 1.4888 - val_label_output_loss: -50.3701\n",
      "Epoch 153/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: -54.9796 - decoded_loss: 0.4978 - label_output_loss: -55.4774 - val_loss: -50.8953 - val_decoded_loss: 1.4976 - val_label_output_loss: -52.3929\n",
      "Epoch 154/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: -55.4140 - decoded_loss: 0.4948 - label_output_loss: -55.9087 - val_loss: -52.3113 - val_decoded_loss: 1.5005 - val_label_output_loss: -53.8117\n",
      "Epoch 155/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: -56.0143 - decoded_loss: 0.5052 - label_output_loss: -56.5194 - val_loss: -52.6366 - val_decoded_loss: 1.4992 - val_label_output_loss: -54.1358\n",
      "Epoch 156/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: -56.3235 - decoded_loss: 0.5002 - label_output_loss: -56.8237 - val_loss: -53.6771 - val_decoded_loss: 1.5082 - val_label_output_loss: -55.1853\n",
      "Epoch 157/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: -56.9647 - decoded_loss: 0.4895 - label_output_loss: -57.4542 - val_loss: -53.8685 - val_decoded_loss: 1.5166 - val_label_output_loss: -55.3851\n",
      "Epoch 158/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: -57.7984 - decoded_loss: 0.4789 - label_output_loss: -58.2773 - val_loss: -52.6316 - val_decoded_loss: 1.5209 - val_label_output_loss: -54.1525\n",
      "Epoch 159/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: -57.8618 - decoded_loss: 0.4968 - label_output_loss: -58.3587 - val_loss: -54.5476 - val_decoded_loss: 1.5310 - val_label_output_loss: -56.0786\n",
      "Epoch 160/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: -58.3835 - decoded_loss: 0.4960 - label_output_loss: -58.8795 - val_loss: -56.7477 - val_decoded_loss: 1.5399 - val_label_output_loss: -58.2877\n",
      "Epoch 161/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: -59.2941 - decoded_loss: 0.4836 - label_output_loss: -59.7777 - val_loss: -56.1534 - val_decoded_loss: 1.5474 - val_label_output_loss: -57.7009\n",
      "Epoch 162/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: -59.4421 - decoded_loss: 0.4922 - label_output_loss: -59.9343 - val_loss: -54.0566 - val_decoded_loss: 1.5536 - val_label_output_loss: -55.6102\n",
      "Epoch 163/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: -59.9583 - decoded_loss: 0.4747 - label_output_loss: -60.4330 - val_loss: -55.1268 - val_decoded_loss: 1.5669 - val_label_output_loss: -56.6937\n",
      "Epoch 164/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: -60.4545 - decoded_loss: 0.4842 - label_output_loss: -60.9386 - val_loss: -55.6035 - val_decoded_loss: 1.5737 - val_label_output_loss: -57.1772\n",
      "Epoch 165/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: -61.2921 - decoded_loss: 0.4813 - label_output_loss: -61.7734 - val_loss: -58.2923 - val_decoded_loss: 1.5935 - val_label_output_loss: -59.8858\n",
      "Epoch 166/1000\n",
      "2/2 [==============================] - 0s 47ms/step - loss: -61.7983 - decoded_loss: 0.4665 - label_output_loss: -62.2648 - val_loss: -59.4729 - val_decoded_loss: 1.6153 - val_label_output_loss: -61.0882\n",
      "Epoch 167/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: -62.2909 - decoded_loss: 0.4913 - label_output_loss: -62.7821 - val_loss: -56.8091 - val_decoded_loss: 1.6263 - val_label_output_loss: -58.4354\n",
      "Epoch 168/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: -62.4205 - decoded_loss: 0.4721 - label_output_loss: -62.8926 - val_loss: -58.3878 - val_decoded_loss: 1.6498 - val_label_output_loss: -60.0376\n",
      "Epoch 169/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: -63.1721 - decoded_loss: 0.4771 - label_output_loss: -63.6492 - val_loss: -59.0812 - val_decoded_loss: 1.6611 - val_label_output_loss: -60.7423\n",
      "Epoch 170/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: -63.6654 - decoded_loss: 0.4639 - label_output_loss: -64.1293 - val_loss: -60.5060 - val_decoded_loss: 1.6704 - val_label_output_loss: -62.1764\n",
      "Epoch 171/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: -63.9663 - decoded_loss: 0.4727 - label_output_loss: -64.4391 - val_loss: -62.3742 - val_decoded_loss: 1.6874 - val_label_output_loss: -64.0616\n",
      "Epoch 172/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: -64.5417 - decoded_loss: 0.4993 - label_output_loss: -65.0410 - val_loss: -61.9268 - val_decoded_loss: 1.6963 - val_label_output_loss: -63.6231\n",
      "Epoch 173/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: -65.1425 - decoded_loss: 0.4574 - label_output_loss: -65.5999 - val_loss: -60.1706 - val_decoded_loss: 1.6969 - val_label_output_loss: -61.8675\n",
      "Epoch 174/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: -65.5889 - decoded_loss: 0.4873 - label_output_loss: -66.0762 - val_loss: -63.1103 - val_decoded_loss: 1.7133 - val_label_output_loss: -64.8235\n",
      "Epoch 175/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: -66.4831 - decoded_loss: 0.4597 - label_output_loss: -66.9428 - val_loss: -62.8798 - val_decoded_loss: 1.7222 - val_label_output_loss: -64.6020\n",
      "Epoch 176/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: -66.4837 - decoded_loss: 0.4895 - label_output_loss: -66.9732 - val_loss: -62.6832 - val_decoded_loss: 1.7337 - val_label_output_loss: -64.4169\n",
      "Epoch 177/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: -67.2871 - decoded_loss: 0.4779 - label_output_loss: -67.7650 - val_loss: -65.6583 - val_decoded_loss: 1.7501 - val_label_output_loss: -67.4085\n",
      "Epoch 178/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: -67.6908 - decoded_loss: 0.4602 - label_output_loss: -68.1510 - val_loss: -64.5012 - val_decoded_loss: 1.7595 - val_label_output_loss: -66.2607\n",
      "Epoch 179/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: -68.4207 - decoded_loss: 0.4629 - label_output_loss: -68.8836 - val_loss: -65.9360 - val_decoded_loss: 1.7839 - val_label_output_loss: -67.7200\n",
      "Epoch 180/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: -68.8862 - decoded_loss: 0.4683 - label_output_loss: -69.3545 - val_loss: -67.4376 - val_decoded_loss: 1.8092 - val_label_output_loss: -69.2468\n",
      "Epoch 181/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: -69.7453 - decoded_loss: 0.4709 - label_output_loss: -70.2162 - val_loss: -65.7152 - val_decoded_loss: 1.8229 - val_label_output_loss: -67.5381\n",
      "Epoch 182/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: -69.9980 - decoded_loss: 0.4816 - label_output_loss: -70.4797 - val_loss: -64.6582 - val_decoded_loss: 1.8428 - val_label_output_loss: -66.5010\n",
      "Epoch 183/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: -70.9416 - decoded_loss: 0.4543 - label_output_loss: -71.3959 - val_loss: -67.6321 - val_decoded_loss: 1.8711 - val_label_output_loss: -69.5032\n",
      "Epoch 184/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: -71.0002 - decoded_loss: 0.4646 - label_output_loss: -71.4648 - val_loss: -67.1284 - val_decoded_loss: 1.8765 - val_label_output_loss: -69.0049\n",
      "Epoch 185/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: -71.9768 - decoded_loss: 0.4628 - label_output_loss: -72.4397 - val_loss: -71.6661 - val_decoded_loss: 1.9014 - val_label_output_loss: -73.5675\n",
      "Epoch 186/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: -72.3112 - decoded_loss: 0.4736 - label_output_loss: -72.7848 - val_loss: -68.1495 - val_decoded_loss: 1.9081 - val_label_output_loss: -70.0576\n",
      "Epoch 187/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: -73.0192 - decoded_loss: 0.4746 - label_output_loss: -73.4938 - val_loss: -65.8507 - val_decoded_loss: 1.9209 - val_label_output_loss: -67.7716\n",
      "Epoch 188/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: -73.6094 - decoded_loss: 0.4764 - label_output_loss: -74.0859 - val_loss: -67.1327 - val_decoded_loss: 1.9419 - val_label_output_loss: -69.0746\n",
      "Epoch 189/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: -73.9253 - decoded_loss: 0.4844 - label_output_loss: -74.4097 - val_loss: -68.7726 - val_decoded_loss: 1.9608 - val_label_output_loss: -70.7334\n",
      "Epoch 190/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: -74.4967 - decoded_loss: 0.4779 - label_output_loss: -74.9746 - val_loss: -73.0748 - val_decoded_loss: 1.9926 - val_label_output_loss: -75.0674\n",
      "Epoch 191/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: -75.1885 - decoded_loss: 0.4564 - label_output_loss: -75.6449 - val_loss: -71.4026 - val_decoded_loss: 2.0150 - val_label_output_loss: -73.4177\n",
      "Epoch 192/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: -75.9375 - decoded_loss: 0.4731 - label_output_loss: -76.4106 - val_loss: -69.9279 - val_decoded_loss: 2.0469 - val_label_output_loss: -71.9748\n",
      "Epoch 193/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: -76.2769 - decoded_loss: 0.4803 - label_output_loss: -76.7572 - val_loss: -69.8652 - val_decoded_loss: 2.0743 - val_label_output_loss: -71.9395\n",
      "Epoch 194/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: -76.8215 - decoded_loss: 0.4840 - label_output_loss: -77.3055 - val_loss: -70.3908 - val_decoded_loss: 2.0821 - val_label_output_loss: -72.4729\n",
      "Epoch 195/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: -77.3934 - decoded_loss: 0.4697 - label_output_loss: -77.8631 - val_loss: -73.5897 - val_decoded_loss: 2.0891 - val_label_output_loss: -75.6788\n",
      "Epoch 196/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: -78.3481 - decoded_loss: 0.4678 - label_output_loss: -78.8158 - val_loss: -74.4958 - val_decoded_loss: 2.1040 - val_label_output_loss: -76.5998\n",
      "Epoch 197/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: -78.7291 - decoded_loss: 0.4525 - label_output_loss: -79.1816 - val_loss: -74.3571 - val_decoded_loss: 2.1295 - val_label_output_loss: -76.4866\n",
      "Epoch 198/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: -79.5525 - decoded_loss: 0.4518 - label_output_loss: -80.0043 - val_loss: -73.7185 - val_decoded_loss: 2.1594 - val_label_output_loss: -75.8779\n",
      "Epoch 199/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: -80.1997 - decoded_loss: 0.4637 - label_output_loss: -80.6635 - val_loss: -74.1028 - val_decoded_loss: 2.2000 - val_label_output_loss: -76.3028\n",
      "Epoch 200/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: -80.6421 - decoded_loss: 0.4468 - label_output_loss: -81.0889 - val_loss: -75.1784 - val_decoded_loss: 2.2396 - val_label_output_loss: -77.4180\n",
      "Epoch 201/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: -80.9879 - decoded_loss: 0.4606 - label_output_loss: -81.4486 - val_loss: -75.4773 - val_decoded_loss: 2.2711 - val_label_output_loss: -77.7484\n",
      "Epoch 202/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: -81.7782 - decoded_loss: 0.4646 - label_output_loss: -82.2427 - val_loss: -76.3028 - val_decoded_loss: 2.3017 - val_label_output_loss: -78.6045\n",
      "Epoch 203/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: -82.8691 - decoded_loss: 0.4447 - label_output_loss: -83.3137 - val_loss: -75.8723 - val_decoded_loss: 2.3357 - val_label_output_loss: -78.2080\n",
      "Epoch 204/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: -83.0475 - decoded_loss: 0.4569 - label_output_loss: -83.5044 - val_loss: -74.7766 - val_decoded_loss: 2.3625 - val_label_output_loss: -77.1391\n",
      "Epoch 205/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: -83.5482 - decoded_loss: 0.4622 - label_output_loss: -84.0104 - val_loss: -76.9185 - val_decoded_loss: 2.3855 - val_label_output_loss: -79.3040\n",
      "Epoch 206/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: -83.8237 - decoded_loss: 0.4471 - label_output_loss: -84.2708 - val_loss: -78.3218 - val_decoded_loss: 2.4076 - val_label_output_loss: -80.7294\n",
      "Epoch 207/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: -84.9139 - decoded_loss: 0.4465 - label_output_loss: -85.3603 - val_loss: -77.7060 - val_decoded_loss: 2.4287 - val_label_output_loss: -80.1347\n",
      "Epoch 208/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: -85.4271 - decoded_loss: 0.4619 - label_output_loss: -85.8890 - val_loss: -77.9663 - val_decoded_loss: 2.4571 - val_label_output_loss: -80.4234\n",
      "Epoch 209/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: -86.0296 - decoded_loss: 0.4619 - label_output_loss: -86.4914 - val_loss: -80.4105 - val_decoded_loss: 2.5045 - val_label_output_loss: -82.9150\n",
      "Epoch 210/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: -86.4967 - decoded_loss: 0.4577 - label_output_loss: -86.9544 - val_loss: -76.3182 - val_decoded_loss: 2.5285 - val_label_output_loss: -78.8466\n",
      "Epoch 211/1000\n",
      "2/2 [==============================] - 0s 48ms/step - loss: -87.1454 - decoded_loss: 0.4400 - label_output_loss: -87.5855 - val_loss: -78.6360 - val_decoded_loss: 2.5777 - val_label_output_loss: -81.2136\n",
      "Epoch 212/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: -87.6372 - decoded_loss: 0.4622 - label_output_loss: -88.0993 - val_loss: -80.6242 - val_decoded_loss: 2.6071 - val_label_output_loss: -83.2313\n",
      "Epoch 213/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: -88.3384 - decoded_loss: 0.4604 - label_output_loss: -88.7988 - val_loss: -81.7786 - val_decoded_loss: 2.6279 - val_label_output_loss: -84.4065\n",
      "Epoch 214/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: -88.5411 - decoded_loss: 0.4443 - label_output_loss: -88.9854 - val_loss: -83.6223 - val_decoded_loss: 2.6486 - val_label_output_loss: -86.2709\n",
      "Epoch 215/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: -89.5141 - decoded_loss: 0.4480 - label_output_loss: -89.9621 - val_loss: -82.2596 - val_decoded_loss: 2.6549 - val_label_output_loss: -84.9145\n",
      "Epoch 216/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: -90.2890 - decoded_loss: 0.4375 - label_output_loss: -90.7265 - val_loss: -83.3922 - val_decoded_loss: 2.6653 - val_label_output_loss: -86.0575\n",
      "Epoch 217/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: -91.4495 - decoded_loss: 0.4416 - label_output_loss: -91.8911 - val_loss: -85.8917 - val_decoded_loss: 2.6899 - val_label_output_loss: -88.5816\n",
      "Epoch 218/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: -91.9946 - decoded_loss: 0.4563 - label_output_loss: -92.4509 - val_loss: -88.4457 - val_decoded_loss: 2.7415 - val_label_output_loss: -91.1873\n",
      "Epoch 219/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: -91.9967 - decoded_loss: 0.4365 - label_output_loss: -92.4332 - val_loss: -85.7131 - val_decoded_loss: 2.7830 - val_label_output_loss: -88.4961\n",
      "Epoch 220/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: -92.9602 - decoded_loss: 0.4540 - label_output_loss: -93.4143 - val_loss: -85.8852 - val_decoded_loss: 2.8308 - val_label_output_loss: -88.7160\n",
      "Epoch 221/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: -93.6337 - decoded_loss: 0.4488 - label_output_loss: -94.0825 - val_loss: -84.8833 - val_decoded_loss: 2.8575 - val_label_output_loss: -87.7408\n",
      "Epoch 222/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: -93.5405 - decoded_loss: 0.4430 - label_output_loss: -93.9835 - val_loss: -86.9478 - val_decoded_loss: 2.9115 - val_label_output_loss: -89.8592\n",
      "Epoch 223/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: -95.1359 - decoded_loss: 0.4540 - label_output_loss: -95.5899 - val_loss: -90.5959 - val_decoded_loss: 2.9758 - val_label_output_loss: -93.5717\n",
      "Epoch 224/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: -95.9477 - decoded_loss: 0.4562 - label_output_loss: -96.4039 - val_loss: -86.1260 - val_decoded_loss: 2.9916 - val_label_output_loss: -89.1176\n",
      "Epoch 225/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: -96.0144 - decoded_loss: 0.4582 - label_output_loss: -96.4726 - val_loss: -90.0657 - val_decoded_loss: 3.0441 - val_label_output_loss: -93.1098\n",
      "Epoch 226/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: -96.8534 - decoded_loss: 0.4591 - label_output_loss: -97.3125 - val_loss: -88.9709 - val_decoded_loss: 3.0615 - val_label_output_loss: -92.0324\n",
      "Epoch 227/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: -97.0044 - decoded_loss: 0.4470 - label_output_loss: -97.4514 - val_loss: -89.8338 - val_decoded_loss: 3.0932 - val_label_output_loss: -92.9271\n",
      "Epoch 228/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: -98.1537 - decoded_loss: 0.4514 - label_output_loss: -98.6051 - val_loss: -95.2023 - val_decoded_loss: 3.1644 - val_label_output_loss: -98.3667\n",
      "Epoch 229/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: -99.2911 - decoded_loss: 0.4426 - label_output_loss: -99.7337 - val_loss: -93.7901 - val_decoded_loss: 3.2058 - val_label_output_loss: -96.9959\n",
      "Epoch 230/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: -99.3063 - decoded_loss: 0.4666 - label_output_loss: -99.7730 - val_loss: -94.4915 - val_decoded_loss: 3.2555 - val_label_output_loss: -97.7471\n",
      "Epoch 231/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: -100.4356 - decoded_loss: 0.4479 - label_output_loss: -100.8835 - val_loss: -97.2633 - val_decoded_loss: 3.3201 - val_label_output_loss: -100.5834\n",
      "Epoch 232/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: -100.3844 - decoded_loss: 0.4550 - label_output_loss: -100.8394 - val_loss: -94.1534 - val_decoded_loss: 3.3498 - val_label_output_loss: -97.5033\n",
      "Epoch 233/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: -101.0277 - decoded_loss: 0.4348 - label_output_loss: -101.4626 - val_loss: -98.3587 - val_decoded_loss: 3.4323 - val_label_output_loss: -101.7911\n",
      "Epoch 234/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: -102.2559 - decoded_loss: 0.4608 - label_output_loss: -102.7167 - val_loss: -95.6935 - val_decoded_loss: 3.4739 - val_label_output_loss: -99.1674\n",
      "Epoch 235/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: -102.9528 - decoded_loss: 0.4423 - label_output_loss: -103.3951 - val_loss: -96.9365 - val_decoded_loss: 3.5167 - val_label_output_loss: -100.4532\n",
      "Epoch 236/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: -103.3959 - decoded_loss: 0.4598 - label_output_loss: -103.8557 - val_loss: -99.4291 - val_decoded_loss: 3.5565 - val_label_output_loss: -102.9857\n",
      "Epoch 237/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: -103.6814 - decoded_loss: 0.4582 - label_output_loss: -104.1397 - val_loss: -97.7231 - val_decoded_loss: 3.5973 - val_label_output_loss: -101.3204\n",
      "Epoch 238/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: -104.7541 - decoded_loss: 0.4407 - label_output_loss: -105.1948 - val_loss: -100.4109 - val_decoded_loss: 3.6646 - val_label_output_loss: -104.0755\n",
      "Epoch 239/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: -105.6217 - decoded_loss: 0.4562 - label_output_loss: -106.0779 - val_loss: -98.5091 - val_decoded_loss: 3.6969 - val_label_output_loss: -102.2059\n",
      "Epoch 240/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: -106.5644 - decoded_loss: 0.4378 - label_output_loss: -107.0022 - val_loss: -100.6347 - val_decoded_loss: 3.7586 - val_label_output_loss: -104.3934\n",
      "Epoch 241/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: -106.8330 - decoded_loss: 0.4519 - label_output_loss: -107.2848 - val_loss: -101.3214 - val_decoded_loss: 3.8048 - val_label_output_loss: -105.1262\n",
      "Epoch 242/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: -107.5765 - decoded_loss: 0.4559 - label_output_loss: -108.0324 - val_loss: -100.9881 - val_decoded_loss: 3.8485 - val_label_output_loss: -104.8366\n",
      "Epoch 243/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: -108.0514 - decoded_loss: 0.4567 - label_output_loss: -108.5081 - val_loss: -104.3372 - val_decoded_loss: 3.9179 - val_label_output_loss: -108.2551\n",
      "Epoch 244/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: -109.4183 - decoded_loss: 0.4584 - label_output_loss: -109.8767 - val_loss: -102.7701 - val_decoded_loss: 3.9704 - val_label_output_loss: -106.7406\n",
      "Epoch 245/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: -109.6133 - decoded_loss: 0.4553 - label_output_loss: -110.0686 - val_loss: -101.8072 - val_decoded_loss: 4.0273 - val_label_output_loss: -105.8344\n",
      "Epoch 246/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: -110.1454 - decoded_loss: 0.4526 - label_output_loss: -110.5980 - val_loss: -106.1511 - val_decoded_loss: 4.0894 - val_label_output_loss: -110.2405\n",
      "Epoch 247/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: -111.2844 - decoded_loss: 0.4481 - label_output_loss: -111.7324 - val_loss: -104.6192 - val_decoded_loss: 4.1240 - val_label_output_loss: -108.7433\n",
      "Epoch 248/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: -111.5249 - decoded_loss: 0.4525 - label_output_loss: -111.9774 - val_loss: -109.5339 - val_decoded_loss: 4.2010 - val_label_output_loss: -113.7349\n",
      "Epoch 249/1000\n",
      "2/2 [==============================] - 0s 68ms/step - loss: -112.2919 - decoded_loss: 0.4533 - label_output_loss: -112.7452 - val_loss: -108.5665 - val_decoded_loss: 4.2722 - val_label_output_loss: -112.8388\n",
      "Epoch 250/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: -113.3493 - decoded_loss: 0.4271 - label_output_loss: -113.7764 - val_loss: -102.7454 - val_decoded_loss: 4.3109 - val_label_output_loss: -107.0563\n",
      "Epoch 251/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: -113.8048 - decoded_loss: 0.4336 - label_output_loss: -114.2383 - val_loss: -109.3258 - val_decoded_loss: 4.4228 - val_label_output_loss: -113.7486\n",
      "Epoch 252/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: -114.3908 - decoded_loss: 0.4447 - label_output_loss: -114.8355 - val_loss: -105.7287 - val_decoded_loss: 4.4737 - val_label_output_loss: -110.2024\n",
      "Epoch 253/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: -115.6811 - decoded_loss: 0.4665 - label_output_loss: -116.1475 - val_loss: -107.6024 - val_decoded_loss: 4.5441 - val_label_output_loss: -112.1466\n",
      "Epoch 254/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: -116.1029 - decoded_loss: 0.4535 - label_output_loss: -116.5564 - val_loss: -109.6727 - val_decoded_loss: 4.6131 - val_label_output_loss: -114.2859\n",
      "Epoch 255/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: -116.8412 - decoded_loss: 0.4585 - label_output_loss: -117.2998 - val_loss: -107.3255 - val_decoded_loss: 4.6635 - val_label_output_loss: -111.9891\n",
      "Epoch 256/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: -117.6086 - decoded_loss: 0.4393 - label_output_loss: -118.0479 - val_loss: -111.1459 - val_decoded_loss: 4.7471 - val_label_output_loss: -115.8931\n",
      "Epoch 257/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: -117.6703 - decoded_loss: 0.4669 - label_output_loss: -118.1372 - val_loss: -111.2729 - val_decoded_loss: 4.8271 - val_label_output_loss: -116.1001\n",
      "Epoch 258/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: -118.4879 - decoded_loss: 0.4582 - label_output_loss: -118.9460 - val_loss: -111.4054 - val_decoded_loss: 4.9144 - val_label_output_loss: -116.3198\n",
      "Epoch 259/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: -120.0875 - decoded_loss: 0.4633 - label_output_loss: -120.5509 - val_loss: -107.3666 - val_decoded_loss: 4.9876 - val_label_output_loss: -112.3542\n",
      "Epoch 260/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: -121.5153 - decoded_loss: 0.4567 - label_output_loss: -121.9720 - val_loss: -107.6614 - val_decoded_loss: 5.0842 - val_label_output_loss: -112.7456\n",
      "Epoch 261/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: -121.7957 - decoded_loss: 0.4291 - label_output_loss: -122.2248 - val_loss: -109.8623 - val_decoded_loss: 5.1797 - val_label_output_loss: -115.0420\n",
      "Epoch 262/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: -122.2555 - decoded_loss: 0.4286 - label_output_loss: -122.6841 - val_loss: -111.7395 - val_decoded_loss: 5.2600 - val_label_output_loss: -116.9995\n",
      "Epoch 263/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: -122.5683 - decoded_loss: 0.4505 - label_output_loss: -123.0188 - val_loss: -113.6728 - val_decoded_loss: 5.3151 - val_label_output_loss: -118.9879\n",
      "Epoch 264/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: -123.8627 - decoded_loss: 0.4437 - label_output_loss: -124.3064 - val_loss: -115.6354 - val_decoded_loss: 5.3783 - val_label_output_loss: -121.0137\n",
      "Epoch 265/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: -124.0672 - decoded_loss: 0.4496 - label_output_loss: -124.5169 - val_loss: -114.6924 - val_decoded_loss: 5.4354 - val_label_output_loss: -120.1278\n",
      "Epoch 266/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: -124.9520 - decoded_loss: 0.4496 - label_output_loss: -125.4016 - val_loss: -116.3496 - val_decoded_loss: 5.5082 - val_label_output_loss: -121.8578\n",
      "Epoch 267/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: -125.4108 - decoded_loss: 0.4214 - label_output_loss: -125.8322 - val_loss: -118.0237 - val_decoded_loss: 5.5779 - val_label_output_loss: -123.6016\n",
      "Epoch 268/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: -126.6351 - decoded_loss: 0.4527 - label_output_loss: -127.0878 - val_loss: -116.8987 - val_decoded_loss: 5.6439 - val_label_output_loss: -122.5426\n",
      "Epoch 269/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: -127.3054 - decoded_loss: 0.4417 - label_output_loss: -127.7471 - val_loss: -123.5087 - val_decoded_loss: 5.7747 - val_label_output_loss: -129.2834\n",
      "Epoch 270/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: -128.1560 - decoded_loss: 0.4561 - label_output_loss: -128.6121 - val_loss: -122.0465 - val_decoded_loss: 5.8521 - val_label_output_loss: -127.8986\n",
      "Epoch 271/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: -128.8812 - decoded_loss: 0.4405 - label_output_loss: -129.3217 - val_loss: -120.4806 - val_decoded_loss: 5.9585 - val_label_output_loss: -126.4391\n",
      "Epoch 272/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: -129.2411 - decoded_loss: 0.4324 - label_output_loss: -129.6735 - val_loss: -120.6762 - val_decoded_loss: 6.1065 - val_label_output_loss: -126.7827\n",
      "Epoch 273/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: -130.2467 - decoded_loss: 0.4648 - label_output_loss: -130.7115 - val_loss: -113.8881 - val_decoded_loss: 6.1839 - val_label_output_loss: -120.0720\n",
      "Epoch 274/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: -129.9131 - decoded_loss: 0.4409 - label_output_loss: -130.3541 - val_loss: -119.5416 - val_decoded_loss: 6.2911 - val_label_output_loss: -125.8327\n",
      "Epoch 275/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: -131.9880 - decoded_loss: 0.4391 - label_output_loss: -132.4271 - val_loss: -119.1387 - val_decoded_loss: 6.3514 - val_label_output_loss: -125.4901\n",
      "Epoch 276/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: -132.9607 - decoded_loss: 0.4262 - label_output_loss: -133.3869 - val_loss: -122.8541 - val_decoded_loss: 6.4442 - val_label_output_loss: -129.2983\n",
      "Epoch 277/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: -133.8551 - decoded_loss: 0.4473 - label_output_loss: -134.3024 - val_loss: -121.9528 - val_decoded_loss: 6.5215 - val_label_output_loss: -128.4743\n",
      "Epoch 278/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: -134.1277 - decoded_loss: 0.4585 - label_output_loss: -134.5862 - val_loss: -121.4741 - val_decoded_loss: 6.6082 - val_label_output_loss: -128.0823\n",
      "Epoch 279/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: -135.1232 - decoded_loss: 0.4286 - label_output_loss: -135.5518 - val_loss: -123.7545 - val_decoded_loss: 6.7223 - val_label_output_loss: -130.4768\n",
      "Epoch 280/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: -135.8137 - decoded_loss: 0.4579 - label_output_loss: -136.2716 - val_loss: -121.9264 - val_decoded_loss: 6.8035 - val_label_output_loss: -128.7299\n",
      "Epoch 281/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: -137.1812 - decoded_loss: 0.4499 - label_output_loss: -137.6310 - val_loss: -126.0853 - val_decoded_loss: 6.9291 - val_label_output_loss: -133.0144\n",
      "Epoch 282/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: -137.1228 - decoded_loss: 0.4280 - label_output_loss: -137.5508 - val_loss: -126.3327 - val_decoded_loss: 7.0410 - val_label_output_loss: -133.3737\n",
      "Epoch 283/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: -138.2164 - decoded_loss: 0.4275 - label_output_loss: -138.6439 - val_loss: -126.4246 - val_decoded_loss: 7.1509 - val_label_output_loss: -133.5755\n",
      "Epoch 284/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: -139.3631 - decoded_loss: 0.4478 - label_output_loss: -139.8109 - val_loss: -125.2228 - val_decoded_loss: 7.2365 - val_label_output_loss: -132.4593\n",
      "Epoch 285/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: -140.1174 - decoded_loss: 0.4548 - label_output_loss: -140.5722 - val_loss: -126.7328 - val_decoded_loss: 7.3212 - val_label_output_loss: -134.0540\n",
      "Epoch 286/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: -140.6128 - decoded_loss: 0.4460 - label_output_loss: -141.0588 - val_loss: -128.3350 - val_decoded_loss: 7.4112 - val_label_output_loss: -135.7463\n",
      "Epoch 287/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: -140.8639 - decoded_loss: 0.4493 - label_output_loss: -141.3133 - val_loss: -127.8859 - val_decoded_loss: 7.4770 - val_label_output_loss: -135.3629\n",
      "Epoch 288/1000\n",
      "2/2 [==============================] - 0s 73ms/step - loss: -142.4554 - decoded_loss: 0.4507 - label_output_loss: -142.9061 - val_loss: -126.0126 - val_decoded_loss: 7.5784 - val_label_output_loss: -133.5910\n",
      "Epoch 289/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: -143.2539 - decoded_loss: 0.4248 - label_output_loss: -143.6787 - val_loss: -129.4109 - val_decoded_loss: 7.7503 - val_label_output_loss: -137.1612\n",
      "Epoch 290/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: -143.7065 - decoded_loss: 0.4257 - label_output_loss: -144.1323 - val_loss: -128.9316 - val_decoded_loss: 7.8966 - val_label_output_loss: -136.8282\n",
      "Epoch 291/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: -145.4052 - decoded_loss: 0.4257 - label_output_loss: -145.8309 - val_loss: -131.0001 - val_decoded_loss: 8.0250 - val_label_output_loss: -139.0251\n",
      "Epoch 292/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: -145.2642 - decoded_loss: 0.4496 - label_output_loss: -145.7139 - val_loss: -129.1754 - val_decoded_loss: 8.1141 - val_label_output_loss: -137.2896\n",
      "Epoch 293/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: -146.2428 - decoded_loss: 0.4390 - label_output_loss: -146.6818 - val_loss: -131.0713 - val_decoded_loss: 8.2183 - val_label_output_loss: -139.2896\n",
      "Epoch 294/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: -146.9089 - decoded_loss: 0.4501 - label_output_loss: -147.3590 - val_loss: -132.3566 - val_decoded_loss: 8.3590 - val_label_output_loss: -140.7156\n",
      "Epoch 295/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: -147.7376 - decoded_loss: 0.4195 - label_output_loss: -148.1572 - val_loss: -133.3445 - val_decoded_loss: 8.5303 - val_label_output_loss: -141.8747\n",
      "Epoch 296/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: -148.5793 - decoded_loss: 0.4190 - label_output_loss: -148.9983 - val_loss: -128.8166 - val_decoded_loss: 8.6734 - val_label_output_loss: -137.4900\n",
      "Epoch 297/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: -149.7320 - decoded_loss: 0.4298 - label_output_loss: -150.1619 - val_loss: -130.3629 - val_decoded_loss: 8.8281 - val_label_output_loss: -139.1910\n",
      "Epoch 298/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: -150.8682 - decoded_loss: 0.4274 - label_output_loss: -151.2956 - val_loss: -128.3027 - val_decoded_loss: 8.9455 - val_label_output_loss: -137.2482\n",
      "Epoch 299/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: -151.5532 - decoded_loss: 0.4297 - label_output_loss: -151.9828 - val_loss: -131.6515 - val_decoded_loss: 9.0952 - val_label_output_loss: -140.7467\n",
      "Epoch 300/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: -152.2432 - decoded_loss: 0.4319 - label_output_loss: -152.6751 - val_loss: -136.0850 - val_decoded_loss: 9.2778 - val_label_output_loss: -145.3628\n",
      "Epoch 301/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: -152.0361 - decoded_loss: 0.4518 - label_output_loss: -152.4878 - val_loss: -134.3481 - val_decoded_loss: 9.3916 - val_label_output_loss: -143.7397\n",
      "Epoch 302/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: -153.3936 - decoded_loss: 0.4322 - label_output_loss: -153.8259 - val_loss: -140.1288 - val_decoded_loss: 9.5859 - val_label_output_loss: -149.7147\n",
      "Epoch 303/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: -154.0611 - decoded_loss: 0.4396 - label_output_loss: -154.5007 - val_loss: -144.0023 - val_decoded_loss: 9.8047 - val_label_output_loss: -153.8071\n",
      "Epoch 304/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: -154.5875 - decoded_loss: 0.4493 - label_output_loss: -155.0368 - val_loss: -134.5522 - val_decoded_loss: 9.8341 - val_label_output_loss: -144.3864\n",
      "Epoch 305/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: -155.3900 - decoded_loss: 0.4622 - label_output_loss: -155.8522 - val_loss: -140.1482 - val_decoded_loss: 9.9774 - val_label_output_loss: -150.1256\n",
      "Epoch 306/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: -156.4840 - decoded_loss: 0.4339 - label_output_loss: -156.9179 - val_loss: -146.0491 - val_decoded_loss: 10.0924 - val_label_output_loss: -156.1416\n",
      "Epoch 307/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: -158.5066 - decoded_loss: 0.4612 - label_output_loss: -158.9678 - val_loss: -142.9768 - val_decoded_loss: 10.1790 - val_label_output_loss: -153.1559\n",
      "Epoch 308/1000\n",
      "2/2 [==============================] - 0s 63ms/step - loss: -158.1644 - decoded_loss: 0.4385 - label_output_loss: -158.6030 - val_loss: -147.1806 - val_decoded_loss: 10.3619 - val_label_output_loss: -157.5425\n",
      "Epoch 309/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: -159.4602 - decoded_loss: 0.4366 - label_output_loss: -159.8968 - val_loss: -145.6727 - val_decoded_loss: 10.5384 - val_label_output_loss: -156.2111\n",
      "Epoch 310/1000\n",
      "2/2 [==============================] - 0s 51ms/step - loss: -160.0665 - decoded_loss: 0.4568 - label_output_loss: -160.5233 - val_loss: -140.1973 - val_decoded_loss: 10.6558 - val_label_output_loss: -150.8531\n",
      "Epoch 311/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: -160.7337 - decoded_loss: 0.4431 - label_output_loss: -161.1767 - val_loss: -146.2155 - val_decoded_loss: 10.8390 - val_label_output_loss: -157.0545\n",
      "Epoch 312/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: -161.5376 - decoded_loss: 0.4278 - label_output_loss: -161.9654 - val_loss: -150.0891 - val_decoded_loss: 11.0283 - val_label_output_loss: -161.1173\n",
      "Epoch 313/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: -163.2394 - decoded_loss: 0.4391 - label_output_loss: -163.6786 - val_loss: -148.6770 - val_decoded_loss: 11.1908 - val_label_output_loss: -159.8677\n",
      "Epoch 314/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: -163.4758 - decoded_loss: 0.4242 - label_output_loss: -163.8999 - val_loss: -142.7597 - val_decoded_loss: 11.3388 - val_label_output_loss: -154.0984\n",
      "Epoch 315/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: -164.3755 - decoded_loss: 0.4526 - label_output_loss: -164.8280 - val_loss: -144.7296 - val_decoded_loss: 11.5701 - val_label_output_loss: -156.2997\n",
      "Epoch 316/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: -165.2154 - decoded_loss: 0.4276 - label_output_loss: -165.6430 - val_loss: -143.7697 - val_decoded_loss: 11.7144 - val_label_output_loss: -155.4841\n",
      "Epoch 317/1000\n",
      "2/2 [==============================] - 0s 49ms/step - loss: -166.8140 - decoded_loss: 0.4289 - label_output_loss: -167.2429 - val_loss: -148.6594 - val_decoded_loss: 11.9327 - val_label_output_loss: -160.5921\n",
      "Epoch 318/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: -167.7065 - decoded_loss: 0.4323 - label_output_loss: -168.1388 - val_loss: -148.9190 - val_decoded_loss: 12.0489 - val_label_output_loss: -160.9679\n",
      "Epoch 319/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: -168.1886 - decoded_loss: 0.4574 - label_output_loss: -168.6460 - val_loss: -144.7243 - val_decoded_loss: 12.0812 - val_label_output_loss: -156.8055\n",
      "Epoch 320/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: -168.7932 - decoded_loss: 0.4608 - label_output_loss: -169.2540 - val_loss: -152.6754 - val_decoded_loss: 12.2753 - val_label_output_loss: -164.9507\n",
      "Epoch 321/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: -170.2061 - decoded_loss: 0.4567 - label_output_loss: -170.6628 - val_loss: -154.5631 - val_decoded_loss: 12.4453 - val_label_output_loss: -167.0085\n",
      "Epoch 322/1000\n",
      "2/2 [==============================] - 0s 50ms/step - loss: -170.8153 - decoded_loss: 0.4509 - label_output_loss: -171.2662 - val_loss: -148.5206 - val_decoded_loss: 12.5302 - val_label_output_loss: -161.0508\n",
      "Epoch 323/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: -171.5230 - decoded_loss: 0.4603 - label_output_loss: -171.9834 - val_loss: -154.3829 - val_decoded_loss: 12.7709 - val_label_output_loss: -167.1537\n",
      "Epoch 324/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: -172.4605 - decoded_loss: 0.4600 - label_output_loss: -172.9205 - val_loss: -150.8691 - val_decoded_loss: 12.9476 - val_label_output_loss: -163.8167\n",
      "Epoch 325/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: -173.1401 - decoded_loss: 0.4377 - label_output_loss: -173.5777 - val_loss: -151.0504 - val_decoded_loss: 13.2095 - val_label_output_loss: -164.2599\n",
      "Epoch 326/1000\n",
      "2/2 [==============================] - 0s 66ms/step - loss: -174.0157 - decoded_loss: 0.4326 - label_output_loss: -174.4483 - val_loss: -154.4567 - val_decoded_loss: 13.4867 - val_label_output_loss: -167.9435\n",
      "Epoch 327/1000\n",
      "2/2 [==============================] - 0s 61ms/step - loss: -175.1961 - decoded_loss: 0.4568 - label_output_loss: -175.6529 - val_loss: -151.1024 - val_decoded_loss: 13.6717 - val_label_output_loss: -164.7741\n",
      "Epoch 328/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: -176.0354 - decoded_loss: 0.4431 - label_output_loss: -176.4786 - val_loss: -149.4142 - val_decoded_loss: 13.8782 - val_label_output_loss: -163.2924\n",
      "Epoch 329/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: -176.6372 - decoded_loss: 0.4545 - label_output_loss: -177.0916 - val_loss: -157.7771 - val_decoded_loss: 14.0912 - val_label_output_loss: -171.8682\n",
      "Epoch 330/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: -177.9937 - decoded_loss: 0.4319 - label_output_loss: -178.4256 - val_loss: -155.5150 - val_decoded_loss: 14.1942 - val_label_output_loss: -169.7092\n",
      "Epoch 331/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: -178.5245 - decoded_loss: 0.4250 - label_output_loss: -178.9495 - val_loss: -159.9221 - val_decoded_loss: 14.3420 - val_label_output_loss: -174.2642\n",
      "Epoch 332/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: -180.4381 - decoded_loss: 0.4455 - label_output_loss: -180.8835 - val_loss: -160.4165 - val_decoded_loss: 14.4468 - val_label_output_loss: -174.8633\n",
      "Epoch 333/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: -180.8949 - decoded_loss: 0.4349 - label_output_loss: -181.3298 - val_loss: -155.1097 - val_decoded_loss: 14.4745 - val_label_output_loss: -169.5843\n",
      "Epoch 334/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: -181.3831 - decoded_loss: 0.4267 - label_output_loss: -181.8098 - val_loss: -160.4930 - val_decoded_loss: 14.7593 - val_label_output_loss: -175.2523\n",
      "Epoch 335/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: -182.5802 - decoded_loss: 0.4466 - label_output_loss: -183.0268 - val_loss: -164.9445 - val_decoded_loss: 15.1128 - val_label_output_loss: -180.0574\n",
      "Epoch 336/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: -182.9167 - decoded_loss: 0.4321 - label_output_loss: -183.3487 - val_loss: -159.7257 - val_decoded_loss: 15.2725 - val_label_output_loss: -174.9982\n",
      "Epoch 337/1000\n",
      "2/2 [==============================] - 0s 53ms/step - loss: -184.6012 - decoded_loss: 0.4378 - label_output_loss: -185.0390 - val_loss: -162.6965 - val_decoded_loss: 15.4819 - val_label_output_loss: -178.1783\n",
      "Epoch 338/1000\n",
      "2/2 [==============================] - 0s 59ms/step - loss: -184.1442 - decoded_loss: 0.4701 - label_output_loss: -184.6143 - val_loss: -161.1097 - val_decoded_loss: 15.6098 - val_label_output_loss: -176.7195\n",
      "Epoch 339/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: -186.0541 - decoded_loss: 0.4691 - label_output_loss: -186.5232 - val_loss: -160.9550 - val_decoded_loss: 15.6903 - val_label_output_loss: -176.6454\n",
      "Epoch 340/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: -187.6031 - decoded_loss: 0.4516 - label_output_loss: -188.0546 - val_loss: -168.7919 - val_decoded_loss: 15.7924 - val_label_output_loss: -184.5844\n",
      "Epoch 341/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: -187.8714 - decoded_loss: 0.4427 - label_output_loss: -188.3141 - val_loss: -169.5910 - val_decoded_loss: 15.9168 - val_label_output_loss: -185.5079\n",
      "Epoch 342/1000\n",
      "2/2 [==============================] - 0s 57ms/step - loss: -189.0668 - decoded_loss: 0.4361 - label_output_loss: -189.5028 - val_loss: -165.5173 - val_decoded_loss: 16.0102 - val_label_output_loss: -181.5275\n",
      "Epoch 343/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: -189.9654 - decoded_loss: 0.4637 - label_output_loss: -190.4291 - val_loss: -165.5953 - val_decoded_loss: 16.2440 - val_label_output_loss: -181.8393\n",
      "Epoch 344/1000\n",
      "2/2 [==============================] - 0s 55ms/step - loss: -190.7126 - decoded_loss: 0.4550 - label_output_loss: -191.1677 - val_loss: -166.1652 - val_decoded_loss: 16.4555 - val_label_output_loss: -182.6207\n",
      "Epoch 345/1000\n",
      "2/2 [==============================] - 0s 52ms/step - loss: -191.9162 - decoded_loss: 0.4522 - label_output_loss: -192.3683 - val_loss: -167.2372 - val_decoded_loss: 16.6527 - val_label_output_loss: -183.8899\n",
      "Epoch 346/1000\n",
      "2/2 [==============================] - 0s 62ms/step - loss: -193.1719 - decoded_loss: 0.4401 - label_output_loss: -193.6120 - val_loss: -168.4123 - val_decoded_loss: 16.8822 - val_label_output_loss: -185.2945\n",
      "Epoch 347/1000\n",
      "2/2 [==============================] - 0s 60ms/step - loss: -193.6717 - decoded_loss: 0.4560 - label_output_loss: -194.1277 - val_loss: -166.3876 - val_decoded_loss: 17.1195 - val_label_output_loss: -183.5071\n",
      "Epoch 348/1000\n",
      "2/2 [==============================] - 0s 56ms/step - loss: -194.7063 - decoded_loss: 0.4545 - label_output_loss: -195.1607 - val_loss: -164.2473 - val_decoded_loss: 17.3669 - val_label_output_loss: -181.6142\n",
      "Epoch 349/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: -195.7466 - decoded_loss: 0.4445 - label_output_loss: -196.1912 - val_loss: -163.1844 - val_decoded_loss: 17.5280 - val_label_output_loss: -180.7124\n",
      "Epoch 350/1000\n",
      "2/2 [==============================] - 0s 58ms/step - loss: -197.0613 - decoded_loss: 0.4580 - label_output_loss: -197.5193 - val_loss: -163.1817 - val_decoded_loss: 17.5551 - val_label_output_loss: -180.7368\n",
      "Epoch 351/1000\n",
      "2/2 [==============================] - 0s 54ms/step - loss: -198.0517 - decoded_loss: 0.4406 - label_output_loss: -198.4924 - val_loss: -165.3208 - val_decoded_loss: 17.6581 - val_label_output_loss: -182.9789\n",
      "FINISH\n"
     ]
    }
   ],
   "source": [
    "TRAIN = True\n",
    "if TRAIN:\n",
    "    autoencoder, encoder = create_autoencoder(X.shape[-1], y.shape[-1],noise=0.1)\n",
    "    autoencoder.fit(X, (X, y),\n",
    "              epochs=1000,\n",
    "              batch_size=4096, \n",
    "              validation_split=0.1,\n",
    "              callbacks=[EarlyStopping('val_loss', patience=10, restore_best_weights=True)])\n",
    "else:\n",
    "    pass\n",
    "encoder.save_weights('/content/drive/MyDrive/Again/encoder.hdf5')\n",
    "encoder.trainable = False\n",
    "print(\"FINISH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qZ1OMTYzPwQW"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "AutoEncoder.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
